{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: datasets 2.18.0\n",
      "Uninstalling datasets-2.18.0:\n",
      "  Successfully uninstalled datasets-2.18.0\n",
      "Found existing installation: huggingface-hub 0.20.3\n",
      "Uninstalling huggingface-hub-0.20.3:\n",
      "  Successfully uninstalled huggingface-hub-0.20.3\n",
      "Found existing installation: fsspec 2023.10.0\n",
      "Uninstalling fsspec-2023.10.0:\n",
      "  Successfully uninstalled fsspec-2023.10.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pip in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (25.0.1)\n",
      "Requirement already satisfied: setuptools in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (78.1.0)\n",
      "Requirement already satisfied: wheel in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (0.45.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting datasets==2.18.0\n",
      "  Using cached datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting huggingface_hub==0.20.3\n",
      "  Using cached huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting fsspec==2023.10.0\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (19.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (3.11.15)\n",
      "Requirement already satisfied: packaging in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib64/python3.9/site-packages (from datasets==2.18.0) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from huggingface_hub==0.20.3) (4.11.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (6.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.18.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.18.0) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.18.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.18.0) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from pandas->datasets==2.18.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from pandas->datasets==2.18.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from pandas->datasets==2.18.0) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.15.0)\n",
      "Using cached datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "Using cached huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: fsspec, huggingface_hub, datasets\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed datasets-2.18.0 fsspec-2023.10.0 huggingface_hub-0.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall datasets huggingface_hub fsspec -y\n",
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install datasets==2.18.0 huggingface_hub==0.20.3 fsspec==2023.10.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.linalg import sqrtm\n",
    "from transformers import BertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weight_list(samples=16, epochs=100):\n",
    "    weights_samples_1 = []\n",
    "    weights_samples_2 = []\n",
    "    weights_samples_fc = []\n",
    "\n",
    "    for _ in tqdm(range(samples)):\n",
    "        # Step 1: Load the TREC dataset\n",
    "        dataset = load_dataset(\"trec\", split=\"train\")\n",
    "        dataset = dataset.train_test_split(test_size=0.2)\n",
    "        train_data = dataset['train']\n",
    "        val_data = dataset['test']\n",
    "\n",
    "        # Step 2: Preprocess the data with a tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        def preprocess(data):\n",
    "            return tokenizer(data['text'], truncation=True, padding=True, max_length=32)\n",
    "\n",
    "        train_data = train_data.map(preprocess, batched=True)\n",
    "        val_data = val_data.map(preprocess, batched=True)\n",
    "\n",
    "        train_data = train_data.rename_column(\"coarse_label\", \"label\")\n",
    "        val_data = val_data.rename_column(\"coarse_label\", \"label\")\n",
    "\n",
    "        train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "        val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "        # Step 3: Create DataLoaders\n",
    "        def collate_fn(batch):\n",
    "            # Ensure all input tensors have the same length by padding them dynamically\n",
    "            input_ids = torch.nn.utils.rnn.pad_sequence([b['input_ids'] for b in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "            attention_mask = torch.nn.utils.rnn.pad_sequence([b['attention_mask'] for b in batch], batch_first=True, padding_value=0)\n",
    "            labels = torch.tensor([b['label'] for b in batch])\n",
    "            return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"label\": labels}\n",
    "\n",
    "        train_loader = DataLoader(train_data, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader = DataLoader(val_data, batch_size=16, collate_fn=collate_fn)\n",
    "\n",
    "        # Step 4: Define a custom PyTorch model\n",
    "        class CustomClassifier(nn.Module):\n",
    "            def __init__(self, input_dim, hidden_dim, num_classes, num_attention_layers=2, vocab_size=30522):\n",
    "                super(CustomClassifier, self).__init__()\n",
    "                \n",
    "                                \n",
    "                self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "                for param in self.bert.parameters():\n",
    "                    param.requires_grad = False  # On gèle BERT\n",
    "                \n",
    "                \n",
    "                # Define a list to store multiple attention layers\n",
    "                self.attention_layers = nn.ModuleList([nn.Linear(input_dim, hidden_dim) for _ in range(num_attention_layers)])\n",
    "                \n",
    "                # Initialise the norm of the attention layers small enough\n",
    "                for layer in self.attention_layers:\n",
    "                    nn.init.normal_(layer.weight, mean=0, std=1e-1)\n",
    "                    nn.init.constant_(layer.bias, 0)\n",
    "                    for param in layer.parameters():\n",
    "                        param.requires_grad = False\n",
    "\n",
    "                # Final fully connected layer for classification\n",
    "                self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "            def _attention_layer(self, x, layer):\n",
    "                # Project the input using the hidden layer\n",
    "                x_new = self.attention_layers[layer](x)\n",
    "\n",
    "                # Self attention (scaled dot-product)\n",
    "                attention_scores = torch.matmul(x_new, x_new.transpose(1, 2)) / x_new.size(-1) ** 0.5  # Scaled attention scores\n",
    "                attention_weights = torch.nn.functional.softmax(attention_scores, dim=-1)\n",
    "\n",
    "                # Apply attention weights to each input in the batch\n",
    "                x = torch.einsum(\"nij,njd->nid\", attention_weights, x)\n",
    "                return x\n",
    "\n",
    "            def forward(self, input_ids, attention_mask):\n",
    "                # Get the embeddings from the input IDs\n",
    "                with torch.no_grad():\n",
    "                    bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    embedded = bert_outputs.last_hidden_state  # shape: (B, M, 768)\n",
    "\n",
    "                \n",
    "                # Apply attention layers\n",
    "                for layer in range(len(self.attention_layers)):\n",
    "                    embedded = self._attention_layer(embedded, layer)\n",
    "                \n",
    "                # Mean pooling (average the token embeddings across the sequence)\n",
    "                pooled_output = embedded.mean(dim=1)  # Average over the token dimension\n",
    "                \n",
    "                # Pass through the final fully connected layer\n",
    "                logits = self.fc(pooled_output)\n",
    "                return logits\n",
    "\n",
    "        model = CustomClassifier(input_dim=768, hidden_dim=4, num_classes=6)\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "\n",
    "        # Step 5: Define optimizer and loss function\n",
    "        optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        weights_attention_1 = []\n",
    "        weights_attention_2 = []\n",
    "        weights_fc = [] \n",
    "\n",
    "\n",
    "        # Step 6: Train the model\n",
    "        def train(epoch):\n",
    "            model.train()\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                weights_attention_1.append(model.attention_layers[0].weight.data.cpu().numpy())\n",
    "                weights_attention_2.append(model.attention_layers[1].weight.data.cpu().numpy())\n",
    "                weights_fc.append(model.fc.weight.data.cpu().numpy())\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "\n",
    "                print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "        # Step 7: Evaluate the model\n",
    "        def evaluate():\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    labels = batch['label'].to(device)\n",
    "\n",
    "                    logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    predictions = torch.argmax(logits, dim=-1)\n",
    "                    correct += (predictions == labels).sum().item()\n",
    "                    total += labels.size(0)\n",
    "\n",
    "            print(f\"Validation Accuracy: {correct / total:.4f}\")\n",
    "\n",
    "        # Run training and evaluation\n",
    "        for epoch in range(epochs):\n",
    "            train(epoch)\n",
    "            evaluate()\n",
    "\n",
    "        weights_samples_1.append(weights_attention_1)\n",
    "        weights_samples_2.append(weights_attention_2)\n",
    "        weights_samples_fc.append(weights_fc)\n",
    "\n",
    "    return weights_samples_1, weights_samples_2, weights_samples_fc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_distance_measure(weights_attention_1, weights_attention_2, weights_fc):\n",
    "\n",
    "    dist_1 = np.zeros(len(weights_attention_1))\n",
    "    dist_2 = np.zeros(len(weights_attention_1))\n",
    "    dist_3 = np.zeros(len(weights_fc))\n",
    "\n",
    "    norm_1 = np.zeros((weights_attention_1[0].shape[0], weights_attention_1[0].shape[0]))\n",
    "    norm_2 = np.zeros_like(norm_1)\n",
    "    mag_1 = np.zeros_like(norm_1)\n",
    "    mag_2 = np.zeros_like(norm_1)\n",
    "\n",
    "    norm_1_final = np.linalg.norm(weights_attention_1[-1], axis=1)\n",
    "    norm_2_final = np.linalg.norm(weights_attention_2[-1], axis=1)\n",
    "\n",
    "\n",
    "    ### THIS USES SQUARED WEIGHTS\n",
    "    weights_attention_1_squared = []\n",
    "    weights_attention_2_squared = []\n",
    "    weights_fc_squared = []\n",
    "\n",
    "    for i in tqdm(range(len(weights_attention_1))):\n",
    "        weights_attention_1_squared.append(np.einsum(\"pi,qi->pq\", weights_attention_1[i],weights_attention_1[i]))\n",
    "        weights_attention_2_squared.append(np.einsum(\"pi,qi->pq\", weights_attention_2[i],weights_attention_2[i]))\n",
    "        weights_fc_squared.append(np.einsum(\"pi,qi->pq\", weights_fc[i], weights_fc[i]))\n",
    "\n",
    "\n",
    "    norm_1_final = np.linalg.norm(weights_attention_1_squared[-1], ord=\"fro\")\n",
    "    norm_2_final = np.linalg.norm(weights_attention_2_squared[-1], ord=\"fro\")\n",
    "    norm_3_final = np.linalg.norm(weights_fc_squared[-1], ord=\"fro\")      \n",
    "    \n",
    "\n",
    "    for i in tqdm(range(len(weights_attention_1))):\n",
    "        norm_1 = np.linalg.norm(weights_attention_1_squared[i], ord=\"fro\")\n",
    "        norm_2 = np.linalg.norm(weights_attention_2_squared[i], ord=\"fro\")\n",
    "        norm_3 = np.linalg.norm(weights_fc_squared[i], ord=\"fro\")\n",
    "\n",
    "        mag_1 = np.einsum(\"pq,qk->pk\", weights_attention_1_squared[i],weights_attention_1_squared[-1])\n",
    "        mag_2 = np.einsum(\"pq,qk->pk\", weights_attention_2_squared[i],weights_attention_2_squared[-1])\n",
    "        mag_3 = np.einsum(\"pq,qk->pk\", weights_fc_squared[i], weights_fc_squared[-1])\n",
    "\n",
    "        dist_1[i] = np.trace(mag_1)/norm_1_final/norm_1\n",
    "        dist_2[i] = np.trace(mag_2)/norm_2_final/norm_2\n",
    "        dist_3[i] = np.trace(mag_3) / norm_3_final / norm_3\n",
    "\n",
    "    return dist_1, dist_2, dist_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for trec contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/trec\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 4361/4361 [00:00<00:00, 21503.31 examples/s]\n",
      "Map: 100%|██████████| 1091/1091 [00:00<00:00, 29209.66 examples/s]\n",
      "/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.5626\n",
      "Validation Accuracy: 0.3914\n",
      "Epoch 1: Loss = 1.4926\n",
      "Validation Accuracy: 0.5032\n",
      "Epoch 2: Loss = 1.1703\n",
      "Validation Accuracy: 0.5490\n",
      "Epoch 3: Loss = 1.4214\n",
      "Validation Accuracy: 0.5839\n",
      "Epoch 4: Loss = 1.1977\n",
      "Validation Accuracy: 0.6040\n",
      "Epoch 5: Loss = 1.0789\n",
      "Validation Accuracy: 0.6196\n",
      "Epoch 6: Loss = 1.3161\n",
      "Validation Accuracy: 0.6544\n",
      "Epoch 7: Loss = 1.3473\n",
      "Validation Accuracy: 0.6572\n",
      "Epoch 8: Loss = 0.9436\n",
      "Validation Accuracy: 0.6700\n",
      "Epoch 9: Loss = 0.8520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:39<00:00, 39.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2730/2730 [00:00<00:00, 52961.57it/s]\n",
      "100%|██████████| 2730/2730 [00:00<00:00, 40942.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.15it/s]\n"
     ]
    }
   ],
   "source": [
    "samples = 1\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "all_dist_samples_1 = []\n",
    "all_dist_samples_2 = []\n",
    "all_dist_samples_fc = []\n",
    "\n",
    "\n",
    "# Ajout : récupération de weights_fc\n",
    "weights_samples_1, weights_samples_2, weights_samples_fc = make_weight_list(samples, epochs)\n",
    "\n",
    "# Initialisation des tableaux de distance\n",
    "T = len(weights_samples_1[0])  # nombre d'epochs (ou itérations de suivi)\n",
    "dist_samples_1 = np.zeros((samples, T))\n",
    "dist_samples_2 = np.zeros((samples, T))\n",
    "dist_samples_fc = np.zeros((samples, T))\n",
    "\n",
    "# Calcul des similarités pour chaque run\n",
    "for i in tqdm(range(samples)):\n",
    "    dist_samples_1[i], dist_samples_2[i], dist_samples_fc[i] = make_distance_measure(\n",
    "        weights_samples_1[i],\n",
    "        weights_samples_2[i],\n",
    "        weights_samples_fc[i]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"realistic_dist_samples_1.npy\", dist_samples_1)\n",
    "np.save(\"realistic_dist_samples_2.npy\", dist_samples_2)\n",
    "np.save(\"realistic_dist_samples_fc.npy\", dist_samples_fc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 341.6x221.6 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"#457B9D\", \"#E63946\", \"#2C5675\", \"#A72833\",\"#1B5E20\"]\n",
    "plt.figure(figsize=(3.416, 2.216))\n",
    "\n",
    "dist_samples_1 = np.load(\"realistic_dist_samples_1.npy\")\n",
    "dist_samples_2 = np.load(\"realistic_dist_samples_2.npy\")\n",
    "dist_samples_fc = np.load(\"realistic_dist_samples_fc.npy\")\n",
    "\n",
    "abs = np.linspace(0, epochs, dist_samples_1.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(abs, dist_samples_1.mean(axis=0), label=r\"$\\mathcal{S}_1$\", color=colors[2])\n",
    "plt.plot(abs, dist_samples_2.mean(axis=0), label=r\"$\\mathcal{S}_2$\", color=colors[3])\n",
    "plt.plot(abs, dist_samples_fc.mean(axis=0), label=r\"$\\mathcal{S}_3$\", color=colors[4])\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
