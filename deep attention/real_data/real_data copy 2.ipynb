{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: datasets 2.18.0\n",
      "Uninstalling datasets-2.18.0:\n",
      "  Successfully uninstalled datasets-2.18.0\n",
      "Found existing installation: huggingface-hub 0.20.3\n",
      "Uninstalling huggingface-hub-0.20.3:\n",
      "  Successfully uninstalled huggingface-hub-0.20.3\n",
      "Found existing installation: fsspec 2023.10.0\n",
      "Uninstalling fsspec-2023.10.0:\n",
      "  Successfully uninstalled fsspec-2023.10.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pip in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (25.0.1)\n",
      "Requirement already satisfied: setuptools in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (78.1.0)\n",
      "Requirement already satisfied: wheel in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (0.45.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting datasets==2.18.0\n",
      "  Using cached datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting huggingface_hub==0.20.3\n",
      "  Using cached huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting fsspec==2023.10.0\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (19.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (3.11.15)\n",
      "Requirement already satisfied: packaging in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from datasets==2.18.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib64/python3.9/site-packages (from datasets==2.18.0) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from huggingface_hub==0.20.3) (4.11.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (6.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.18.0) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.18.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.18.0) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.18.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.18.0) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from pandas->datasets==2.18.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from pandas->datasets==2.18.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages (from pandas->datasets==2.18.0) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.15.0)\n",
      "Using cached datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "Using cached huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: fsspec, huggingface_hub, datasets\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pencv-python (/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed datasets-2.18.0 fsspec-2023.10.0 huggingface_hub-0.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall datasets huggingface_hub fsspec -y\n",
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install datasets==2.18.0 huggingface_hub==0.20.3 fsspec==2023.10.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.linalg import sqrtm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weight_list(samples=16, epochs=100):\n",
    "    weights_samples_1 = []\n",
    "    weights_samples_2 = []\n",
    "    weights_samples_fc = []\n",
    "\n",
    "    for _ in tqdm(range(samples)):\n",
    "        # Step 1: Load the TREC dataset\n",
    "        dataset = load_dataset(\"trec\", split=\"train\")\n",
    "        dataset = dataset.train_test_split(test_size=0.2)\n",
    "        train_data = dataset['train']\n",
    "        val_data = dataset['test']\n",
    "\n",
    "        # Step 2: Preprocess the data with a tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        def preprocess(data):\n",
    "            return tokenizer(data['text'], truncation=True, padding=True, max_length=32)\n",
    "\n",
    "        train_data = train_data.map(preprocess, batched=True)\n",
    "        val_data = val_data.map(preprocess, batched=True)\n",
    "\n",
    "        train_data = train_data.rename_column(\"coarse_label\", \"label\")\n",
    "        val_data = val_data.rename_column(\"coarse_label\", \"label\")\n",
    "\n",
    "        train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "        val_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "        # Step 3: Create DataLoaders\n",
    "        def collate_fn(batch):\n",
    "            # Ensure all input tensors have the same length by padding them dynamically\n",
    "            input_ids = torch.nn.utils.rnn.pad_sequence([b['input_ids'] for b in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "            attention_mask = torch.nn.utils.rnn.pad_sequence([b['attention_mask'] for b in batch], batch_first=True, padding_value=0)\n",
    "            labels = torch.tensor([b['label'] for b in batch])\n",
    "            return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"label\": labels}\n",
    "\n",
    "        train_loader = DataLoader(train_data, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader = DataLoader(val_data, batch_size=16, collate_fn=collate_fn)\n",
    "\n",
    "        # Step 4: Define a custom PyTorch model\n",
    "        class CustomClassifier(nn.Module):\n",
    "            def __init__(self, input_dim, hidden_dim, num_classes, num_attention_layers=2, vocab_size=30522):\n",
    "                super(CustomClassifier, self).__init__()\n",
    "                \n",
    "                # Embedding layer to map token IDs to embeddings\n",
    "                self.embedding = nn.Embedding(vocab_size, input_dim)  # vocab_size is typically 30522 for BERT\n",
    "                \n",
    "                # Define a list to store multiple attention layers\n",
    "                self.attention_layers = nn.ModuleList([nn.Linear(input_dim, hidden_dim) for _ in range(num_attention_layers)])\n",
    "                \n",
    "                # Initialise the norm of the attention layers small enough\n",
    "                for layer in self.attention_layers:\n",
    "                    nn.init.normal_(layer.weight, mean=0, std=1e-1)\n",
    "                    nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "                # Final fully connected layer for classification\n",
    "                self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "            def _attention_layer(self, x, layer):\n",
    "                # Project the input using the hidden layer\n",
    "                x_new = self.attention_layers[layer](x)\n",
    "\n",
    "                # Self attention (scaled dot-product)\n",
    "                attention_scores = torch.matmul(x_new, x_new.transpose(1, 2)) / x_new.size(-1) ** 0.5  # Scaled attention scores\n",
    "                attention_weights = torch.nn.functional.softmax(attention_scores, dim=-1)\n",
    "\n",
    "                # Apply attention weights to each input in the batch\n",
    "                x = torch.einsum(\"nij,njd->nid\", attention_weights, x)\n",
    "                return x\n",
    "\n",
    "            def forward(self, input_ids, attention_mask):\n",
    "                # Get the embeddings from the input IDs\n",
    "                embedded = self.embedding(input_ids)\n",
    "                \n",
    "                # Apply attention layers\n",
    "                for layer in range(len(self.attention_layers)):\n",
    "                    embedded = self._attention_layer(embedded, layer)\n",
    "                \n",
    "                # Mean pooling (average the token embeddings across the sequence)\n",
    "                pooled_output = embedded.mean(dim=1)  # Average over the token dimension\n",
    "                \n",
    "                # Pass through the final fully connected layer\n",
    "                logits = self.fc(pooled_output)\n",
    "                return logits\n",
    "\n",
    "        model = CustomClassifier(input_dim=128, hidden_dim=256, num_classes=6)\n",
    "\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "\n",
    "        # Step 5: Define optimizer and loss function\n",
    "        optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        weights_attention_1 = []\n",
    "        weights_attention_2 = []\n",
    "        weights_fc = [] \n",
    "\n",
    "\n",
    "        # Step 6: Train the model\n",
    "        def train(epoch):\n",
    "            model.train()\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                weights_attention_1.append(model.attention_layers[0].weight.data.cpu().numpy())\n",
    "                weights_attention_2.append(model.attention_layers[1].weight.data.cpu().numpy())\n",
    "                weights_fc.append(model.fc.weight.data.cpu().numpy())\n",
    "\n",
    "\n",
    "            print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "        # Step 7: Evaluate the model\n",
    "        def evaluate():\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    labels = batch['label'].to(device)\n",
    "\n",
    "                    logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    predictions = torch.argmax(logits, dim=-1)\n",
    "                    correct += (predictions == labels).sum().item()\n",
    "                    total += labels.size(0)\n",
    "\n",
    "            print(f\"Validation Accuracy: {correct / total:.4f}\")\n",
    "\n",
    "        # Run training and evaluation\n",
    "        for epoch in range(epochs):\n",
    "            train(epoch)\n",
    "            evaluate()\n",
    "\n",
    "        weights_samples_1.append(weights_attention_1)\n",
    "        weights_samples_2.append(weights_attention_2)\n",
    "        weights_samples_fc.append(weights_fc)\n",
    "\n",
    "    return weights_samples_1, weights_samples_2, weights_samples_fc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_distance_measure(weights_attention_1, weights_attention_2, weights_fc):\n",
    "\n",
    "    dist_1 = np.zeros(len(weights_attention_1))\n",
    "    dist_2 = np.zeros(len(weights_attention_1))\n",
    "    dist_3 = np.zeros(len(weights_fc))\n",
    "\n",
    "    norm_1 = np.zeros((weights_attention_1[0].shape[0], weights_attention_1[0].shape[0]))\n",
    "    norm_2 = np.zeros_like(norm_1)\n",
    "    mag_1 = np.zeros_like(norm_1)\n",
    "    mag_2 = np.zeros_like(norm_1)\n",
    "\n",
    "    norm_1_final = np.linalg.norm(weights_attention_1[-1], axis=1)\n",
    "    norm_2_final = np.linalg.norm(weights_attention_2[-1], axis=1)\n",
    "\n",
    "\n",
    "    ### THIS USES SQUARED WEIGHTS\n",
    "    weights_attention_1_squared = []\n",
    "    weights_attention_2_squared = []\n",
    "    weights_fc_squared = []\n",
    "\n",
    "    for i in tqdm(range(len(weights_attention_1))):\n",
    "        weights_attention_1_squared.append(np.einsum(\"pi,qi->pq\", weights_attention_1[i],weights_attention_1[i]))\n",
    "        weights_attention_2_squared.append(np.einsum(\"pi,qi->pq\", weights_attention_2[i],weights_attention_2[i]))\n",
    "        weights_fc_squared.append(np.einsum(\"pi,qi->pq\", weights_fc[i], weights_fc[i]))\n",
    "\n",
    "\n",
    "    norm_1_final = np.linalg.norm(weights_attention_1_squared[-1], ord=\"fro\")\n",
    "    norm_2_final = np.linalg.norm(weights_attention_2_squared[-1], ord=\"fro\")\n",
    "    norm_3_final = np.linalg.norm(weights_fc_squared[-1], ord=\"fro\")      \n",
    "    \n",
    "\n",
    "    for i in tqdm(range(len(weights_attention_1))):\n",
    "        norm_1 = np.linalg.norm(weights_attention_1_squared[i], ord=\"fro\")\n",
    "        norm_2 = np.linalg.norm(weights_attention_2_squared[i], ord=\"fro\")\n",
    "        norm_3 = np.linalg.norm(weights_fc_squared[i], ord=\"fro\")\n",
    "\n",
    "        mag_1 = np.einsum(\"pq,qk->pk\", weights_attention_1_squared[i],weights_attention_1_squared[-1])\n",
    "        mag_2 = np.einsum(\"pq,qk->pk\", weights_attention_2_squared[i],weights_attention_2_squared[-1])\n",
    "        mag_3 = np.einsum(\"pq,qk->pk\", weights_fc_squared[i], weights_fc_squared[-1])\n",
    "\n",
    "        dist_1[i] = np.trace(mag_1)/norm_1_final/norm_1\n",
    "        dist_2[i] = np.trace(mag_2)/norm_2_final/norm_2\n",
    "        dist_3[i] = np.trace(mag_3) / norm_3_final / norm_3\n",
    "\n",
    "    return dist_1, dist_2, dist_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for trec contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/trec\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 4361/4361 [00:00<00:00, 15753.28 examples/s]\n",
      "Map: 100%|██████████| 1091/1091 [00:00<00:00, 28825.29 examples/s]\n",
      "/users/eleves-b/2022/elias.ben-rhouma/.local/lib/python3.9/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.6772\n",
      "Validation Accuracy: 0.2071\n",
      "Epoch 1: Loss = 1.6819\n",
      "Validation Accuracy: 0.2566\n",
      "Epoch 2: Loss = 1.7373\n",
      "Validation Accuracy: 0.2521\n",
      "Epoch 3: Loss = 1.6112\n",
      "Validation Accuracy: 0.2686\n",
      "Epoch 4: Loss = 1.6459\n",
      "Validation Accuracy: 0.2731\n",
      "Epoch 5: Loss = 1.6588\n",
      "Validation Accuracy: 0.2933\n",
      "Epoch 6: Loss = 1.5195\n",
      "Validation Accuracy: 0.2997\n",
      "Epoch 7: Loss = 1.8843\n",
      "Validation Accuracy: 0.3236\n",
      "Epoch 8: Loss = 1.5732\n",
      "Validation Accuracy: 0.3437\n",
      "Epoch 9: Loss = 1.6211\n",
      "Validation Accuracy: 0.3327\n",
      "Epoch 10: Loss = 1.5665\n",
      "Validation Accuracy: 0.3556\n",
      "Epoch 11: Loss = 1.9667\n",
      "Validation Accuracy: 0.3602\n",
      "Epoch 12: Loss = 1.6425\n",
      "Validation Accuracy: 0.3721\n",
      "Epoch 13: Loss = 1.6403\n",
      "Validation Accuracy: 0.3758\n",
      "Epoch 14: Loss = 1.5348\n",
      "Validation Accuracy: 0.3923\n",
      "Epoch 15: Loss = 1.5545\n",
      "Validation Accuracy: 0.4079\n",
      "Epoch 16: Loss = 1.4879\n",
      "Validation Accuracy: 0.4005\n",
      "Epoch 17: Loss = 1.5739\n",
      "Validation Accuracy: 0.4253\n",
      "Epoch 18: Loss = 1.5018\n",
      "Validation Accuracy: 0.4335\n",
      "Epoch 19: Loss = 1.4848\n",
      "Validation Accuracy: 0.4262\n",
      "Epoch 20: Loss = 1.5598\n",
      "Validation Accuracy: 0.4280\n",
      "Epoch 21: Loss = 1.5520\n",
      "Validation Accuracy: 0.4409\n",
      "Epoch 22: Loss = 1.5347\n",
      "Validation Accuracy: 0.4326\n",
      "Epoch 23: Loss = 1.4561\n",
      "Validation Accuracy: 0.4620\n",
      "Epoch 24: Loss = 1.4339\n",
      "Validation Accuracy: 0.4629\n",
      "Epoch 25: Loss = 1.4742\n",
      "Validation Accuracy: 0.4592\n",
      "Epoch 26: Loss = 1.3947\n",
      "Validation Accuracy: 0.4702\n",
      "Epoch 27: Loss = 1.4093\n",
      "Validation Accuracy: 0.4812\n",
      "Epoch 28: Loss = 1.3888\n",
      "Validation Accuracy: 0.4702\n",
      "Epoch 29: Loss = 1.4637\n",
      "Validation Accuracy: 0.4995\n",
      "Epoch 30: Loss = 1.5275\n",
      "Validation Accuracy: 0.4940\n",
      "Epoch 31: Loss = 1.4415\n",
      "Validation Accuracy: 0.4867\n",
      "Epoch 32: Loss = 1.3781\n",
      "Validation Accuracy: 0.4922\n",
      "Epoch 33: Loss = 1.4175\n",
      "Validation Accuracy: 0.5252\n",
      "Epoch 34: Loss = 1.6561\n",
      "Validation Accuracy: 0.5298\n",
      "Epoch 35: Loss = 1.3554\n",
      "Validation Accuracy: 0.5335\n",
      "Epoch 36: Loss = 1.3874\n",
      "Validation Accuracy: 0.5399\n",
      "Epoch 37: Loss = 1.4641\n",
      "Validation Accuracy: 0.5390\n",
      "Epoch 38: Loss = 1.6572\n",
      "Validation Accuracy: 0.5545\n",
      "Epoch 39: Loss = 1.3609\n",
      "Validation Accuracy: 0.5518\n",
      "Epoch 40: Loss = 0.9668\n",
      "Validation Accuracy: 0.5527\n",
      "Epoch 41: Loss = 1.3333\n",
      "Validation Accuracy: 0.5582\n",
      "Epoch 42: Loss = 1.3038\n",
      "Validation Accuracy: 0.5573\n",
      "Epoch 43: Loss = 1.2537\n",
      "Validation Accuracy: 0.5610\n",
      "Epoch 44: Loss = 1.3119\n",
      "Validation Accuracy: 0.5646\n",
      "Epoch 45: Loss = 1.1387\n",
      "Validation Accuracy: 0.5646\n",
      "Epoch 46: Loss = 1.1449\n",
      "Validation Accuracy: 0.5610\n",
      "Epoch 47: Loss = 1.2320\n",
      "Validation Accuracy: 0.5665\n",
      "Epoch 48: Loss = 1.1006\n",
      "Validation Accuracy: 0.5720\n",
      "Epoch 49: Loss = 1.5959\n",
      "Validation Accuracy: 0.5738\n",
      "Epoch 50: Loss = 1.1511\n",
      "Validation Accuracy: 0.5765\n",
      "Epoch 51: Loss = 0.9458\n",
      "Validation Accuracy: 0.5710\n",
      "Epoch 52: Loss = 0.8139\n",
      "Validation Accuracy: 0.5720\n",
      "Epoch 53: Loss = 1.1986\n",
      "Validation Accuracy: 0.5710\n",
      "Epoch 54: Loss = 1.2206\n",
      "Validation Accuracy: 0.5710\n",
      "Epoch 55: Loss = 1.3637\n",
      "Validation Accuracy: 0.5793\n",
      "Epoch 56: Loss = 1.5653\n",
      "Validation Accuracy: 0.5784\n",
      "Epoch 57: Loss = 0.9179\n",
      "Validation Accuracy: 0.5793\n",
      "Epoch 58: Loss = 1.3434\n",
      "Validation Accuracy: 0.5830\n",
      "Epoch 59: Loss = 0.8903\n",
      "Validation Accuracy: 0.5967\n",
      "Epoch 60: Loss = 0.7404\n",
      "Validation Accuracy: 0.5894\n",
      "Epoch 61: Loss = 0.7286\n",
      "Validation Accuracy: 0.5912\n",
      "Epoch 62: Loss = 1.2649\n",
      "Validation Accuracy: 0.5894\n",
      "Epoch 63: Loss = 0.9701\n",
      "Validation Accuracy: 0.5765\n",
      "Epoch 64: Loss = 0.5758\n",
      "Validation Accuracy: 0.5738\n",
      "Epoch 65: Loss = 0.7882\n",
      "Validation Accuracy: 0.5848\n",
      "Epoch 66: Loss = 0.5875\n",
      "Validation Accuracy: 0.5848\n",
      "Epoch 67: Loss = 1.0728\n",
      "Validation Accuracy: 0.5885\n",
      "Epoch 68: Loss = 1.1789\n",
      "Validation Accuracy: 0.5930\n",
      "Epoch 69: Loss = 0.9294\n",
      "Validation Accuracy: 0.5985\n",
      "Epoch 70: Loss = 1.2607\n",
      "Validation Accuracy: 0.5985\n",
      "Epoch 71: Loss = 1.0969\n",
      "Validation Accuracy: 0.5995\n",
      "Epoch 72: Loss = 1.5460\n",
      "Validation Accuracy: 0.6104\n",
      "Epoch 73: Loss = 0.9129\n",
      "Validation Accuracy: 0.6150\n",
      "Epoch 74: Loss = 0.7913\n",
      "Validation Accuracy: 0.6095\n",
      "Epoch 75: Loss = 0.7868\n",
      "Validation Accuracy: 0.6242\n",
      "Epoch 76: Loss = 0.5784\n",
      "Validation Accuracy: 0.6288\n",
      "Epoch 77: Loss = 1.1491\n",
      "Validation Accuracy: 0.6315\n",
      "Epoch 78: Loss = 0.4834\n",
      "Validation Accuracy: 0.6269\n",
      "Epoch 79: Loss = 0.8233\n",
      "Validation Accuracy: 0.6315\n",
      "Epoch 80: Loss = 0.5769\n",
      "Validation Accuracy: 0.6389\n",
      "Epoch 81: Loss = 1.2881\n",
      "Validation Accuracy: 0.6407\n",
      "Epoch 82: Loss = 1.4444\n",
      "Validation Accuracy: 0.6444\n",
      "Epoch 83: Loss = 1.1017\n",
      "Validation Accuracy: 0.6453\n",
      "Epoch 84: Loss = 1.3050\n",
      "Validation Accuracy: 0.6480\n",
      "Epoch 85: Loss = 1.0429\n",
      "Validation Accuracy: 0.6398\n",
      "Epoch 86: Loss = 0.8207\n",
      "Validation Accuracy: 0.6389\n",
      "Epoch 87: Loss = 0.8124\n",
      "Validation Accuracy: 0.6462\n",
      "Epoch 88: Loss = 1.3251\n",
      "Validation Accuracy: 0.6499\n",
      "Epoch 89: Loss = 0.5542\n",
      "Validation Accuracy: 0.6517\n",
      "Epoch 90: Loss = 0.6854\n",
      "Validation Accuracy: 0.6462\n",
      "Epoch 91: Loss = 0.9518\n",
      "Validation Accuracy: 0.6480\n",
      "Epoch 92: Loss = 0.9861\n",
      "Validation Accuracy: 0.6480\n",
      "Epoch 93: Loss = 0.9758\n",
      "Validation Accuracy: 0.6544\n",
      "Epoch 94: Loss = 0.4961\n",
      "Validation Accuracy: 0.6554\n",
      "Epoch 95: Loss = 0.6271\n",
      "Validation Accuracy: 0.6618\n",
      "Epoch 96: Loss = 0.8372\n",
      "Validation Accuracy: 0.6535\n",
      "Epoch 97: Loss = 0.9139\n",
      "Validation Accuracy: 0.6563\n",
      "Epoch 98: Loss = 1.0232\n",
      "Validation Accuracy: 0.6535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:23<12:32, 83.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Loss = 0.4202\n",
      "Validation Accuracy: 0.6572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4361/4361 [00:00<00:00, 20547.45 examples/s]\n",
      "Map: 100%|██████████| 1091/1091 [00:00<00:00, 28061.48 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.6440\n",
      "Validation Accuracy: 0.2154\n",
      "Epoch 1: Loss = 1.6677\n",
      "Validation Accuracy: 0.2566\n",
      "Epoch 2: Loss = 1.5736\n",
      "Validation Accuracy: 0.2594\n",
      "Epoch 3: Loss = 1.5589\n",
      "Validation Accuracy: 0.2750\n",
      "Epoch 4: Loss = 1.5658\n",
      "Validation Accuracy: 0.2942\n",
      "Epoch 5: Loss = 1.6371\n",
      "Validation Accuracy: 0.3098\n",
      "Epoch 6: Loss = 1.5794\n",
      "Validation Accuracy: 0.2869\n",
      "Epoch 7: Loss = 1.5414\n",
      "Validation Accuracy: 0.3171\n",
      "Epoch 8: Loss = 1.6746\n",
      "Validation Accuracy: 0.3391\n",
      "Epoch 9: Loss = 1.5968\n",
      "Validation Accuracy: 0.3520\n",
      "Epoch 10: Loss = 1.5172\n",
      "Validation Accuracy: 0.3630\n",
      "Epoch 11: Loss = 1.6937\n",
      "Validation Accuracy: 0.3666\n",
      "Epoch 12: Loss = 1.6035\n",
      "Validation Accuracy: 0.3776\n",
      "Epoch 13: Loss = 1.5244\n",
      "Validation Accuracy: 0.3731\n",
      "Epoch 14: Loss = 1.5537\n",
      "Validation Accuracy: 0.3813\n",
      "Epoch 15: Loss = 1.6012\n",
      "Validation Accuracy: 0.3886\n",
      "Epoch 16: Loss = 1.5871\n",
      "Validation Accuracy: 0.4015\n",
      "Epoch 17: Loss = 1.8094\n",
      "Validation Accuracy: 0.4015\n",
      "Epoch 18: Loss = 1.9654\n",
      "Validation Accuracy: 0.3987\n",
      "Epoch 19: Loss = 1.5282\n",
      "Validation Accuracy: 0.4106\n",
      "Epoch 20: Loss = 1.4797\n",
      "Validation Accuracy: 0.4180\n",
      "Epoch 21: Loss = 1.5011\n",
      "Validation Accuracy: 0.4180\n",
      "Epoch 22: Loss = 1.5783\n",
      "Validation Accuracy: 0.4235\n",
      "Epoch 23: Loss = 1.4238\n",
      "Validation Accuracy: 0.4308\n",
      "Epoch 24: Loss = 1.5378\n",
      "Validation Accuracy: 0.4372\n",
      "Epoch 25: Loss = 1.3819\n",
      "Validation Accuracy: 0.4418\n",
      "Epoch 26: Loss = 1.5323\n",
      "Validation Accuracy: 0.4436\n",
      "Epoch 27: Loss = 1.7136\n",
      "Validation Accuracy: 0.4436\n",
      "Epoch 28: Loss = 1.3636\n",
      "Validation Accuracy: 0.4445\n",
      "Epoch 29: Loss = 1.4243\n",
      "Validation Accuracy: 0.4528\n",
      "Epoch 30: Loss = 1.1943\n",
      "Validation Accuracy: 0.4610\n",
      "Epoch 31: Loss = 1.4926\n",
      "Validation Accuracy: 0.4601\n",
      "Epoch 32: Loss = 1.6632\n",
      "Validation Accuracy: 0.4675\n",
      "Epoch 33: Loss = 1.9008\n",
      "Validation Accuracy: 0.4693\n",
      "Epoch 34: Loss = 1.4771\n",
      "Validation Accuracy: 0.4757\n",
      "Epoch 35: Loss = 1.2728\n",
      "Validation Accuracy: 0.4748\n",
      "Epoch 36: Loss = 1.2283\n",
      "Validation Accuracy: 0.4766\n",
      "Epoch 37: Loss = 1.2426\n",
      "Validation Accuracy: 0.4876\n",
      "Epoch 38: Loss = 1.0860\n",
      "Validation Accuracy: 0.4812\n",
      "Epoch 39: Loss = 0.9696\n",
      "Validation Accuracy: 0.4876\n",
      "Epoch 40: Loss = 1.6484\n",
      "Validation Accuracy: 0.4876\n",
      "Epoch 41: Loss = 1.1092\n",
      "Validation Accuracy: 0.4885\n",
      "Epoch 42: Loss = 1.3322\n",
      "Validation Accuracy: 0.4922\n",
      "Epoch 43: Loss = 1.6143\n",
      "Validation Accuracy: 0.5060\n",
      "Epoch 44: Loss = 1.5547\n",
      "Validation Accuracy: 0.4986\n",
      "Epoch 45: Loss = 1.2610\n",
      "Validation Accuracy: 0.4977\n",
      "Epoch 46: Loss = 1.2216\n",
      "Validation Accuracy: 0.4940\n",
      "Epoch 47: Loss = 1.1546\n",
      "Validation Accuracy: 0.5032\n",
      "Epoch 48: Loss = 1.6644\n",
      "Validation Accuracy: 0.5023\n",
      "Epoch 49: Loss = 1.2626\n",
      "Validation Accuracy: 0.5050\n",
      "Epoch 50: Loss = 1.3352\n",
      "Validation Accuracy: 0.5179\n",
      "Epoch 51: Loss = 0.8863\n",
      "Validation Accuracy: 0.5133\n",
      "Epoch 52: Loss = 1.3995\n",
      "Validation Accuracy: 0.5160\n",
      "Epoch 53: Loss = 1.1694\n",
      "Validation Accuracy: 0.5289\n",
      "Epoch 54: Loss = 1.3211\n",
      "Validation Accuracy: 0.5500\n",
      "Epoch 55: Loss = 1.2428\n",
      "Validation Accuracy: 0.5665\n",
      "Epoch 56: Loss = 0.9388\n",
      "Validation Accuracy: 0.5637\n",
      "Epoch 57: Loss = 1.6492\n",
      "Validation Accuracy: 0.5683\n",
      "Epoch 58: Loss = 0.6121\n",
      "Validation Accuracy: 0.5619\n",
      "Epoch 59: Loss = 0.8023\n",
      "Validation Accuracy: 0.5820\n",
      "Epoch 60: Loss = 1.1343\n",
      "Validation Accuracy: 0.5866\n",
      "Epoch 61: Loss = 1.1600\n",
      "Validation Accuracy: 0.5775\n",
      "Epoch 62: Loss = 1.3076\n",
      "Validation Accuracy: 0.5875\n",
      "Epoch 63: Loss = 1.3346\n",
      "Validation Accuracy: 0.5894\n",
      "Epoch 64: Loss = 1.2336\n",
      "Validation Accuracy: 0.5912\n",
      "Epoch 65: Loss = 1.0796\n",
      "Validation Accuracy: 0.6013\n",
      "Epoch 66: Loss = 0.9164\n",
      "Validation Accuracy: 0.5912\n",
      "Epoch 67: Loss = 1.2011\n",
      "Validation Accuracy: 0.6040\n",
      "Epoch 68: Loss = 0.8406\n",
      "Validation Accuracy: 0.6104\n",
      "Epoch 69: Loss = 1.1234\n",
      "Validation Accuracy: 0.6049\n",
      "Epoch 70: Loss = 0.9428\n",
      "Validation Accuracy: 0.6150\n",
      "Epoch 71: Loss = 0.9903\n",
      "Validation Accuracy: 0.6205\n",
      "Epoch 72: Loss = 0.5402\n",
      "Validation Accuracy: 0.6178\n",
      "Epoch 73: Loss = 1.1731\n",
      "Validation Accuracy: 0.6279\n",
      "Epoch 74: Loss = 0.8540\n",
      "Validation Accuracy: 0.6306\n",
      "Epoch 75: Loss = 1.0228\n",
      "Validation Accuracy: 0.6315\n",
      "Epoch 76: Loss = 1.1107\n",
      "Validation Accuracy: 0.6379\n",
      "Epoch 77: Loss = 0.7681\n",
      "Validation Accuracy: 0.6379\n",
      "Epoch 78: Loss = 1.2416\n",
      "Validation Accuracy: 0.6370\n",
      "Epoch 79: Loss = 0.6905\n",
      "Validation Accuracy: 0.6389\n",
      "Epoch 80: Loss = 1.0645\n",
      "Validation Accuracy: 0.6453\n",
      "Epoch 81: Loss = 1.1382\n",
      "Validation Accuracy: 0.6444\n",
      "Epoch 82: Loss = 0.9759\n",
      "Validation Accuracy: 0.6471\n",
      "Epoch 83: Loss = 0.8111\n",
      "Validation Accuracy: 0.6499\n",
      "Epoch 84: Loss = 0.7986\n",
      "Validation Accuracy: 0.6526\n",
      "Epoch 85: Loss = 0.9665\n",
      "Validation Accuracy: 0.6544\n",
      "Epoch 86: Loss = 0.8891\n",
      "Validation Accuracy: 0.6544\n",
      "Epoch 87: Loss = 0.8585\n",
      "Validation Accuracy: 0.6572\n",
      "Epoch 88: Loss = 0.6771\n",
      "Validation Accuracy: 0.6627\n",
      "Epoch 89: Loss = 0.7564\n",
      "Validation Accuracy: 0.6618\n",
      "Epoch 90: Loss = 1.1106\n",
      "Validation Accuracy: 0.6700\n",
      "Epoch 91: Loss = 0.6826\n",
      "Validation Accuracy: 0.6664\n",
      "Epoch 92: Loss = 0.9880\n",
      "Validation Accuracy: 0.6673\n",
      "Epoch 93: Loss = 0.2307\n",
      "Validation Accuracy: 0.6700\n",
      "Epoch 94: Loss = 0.8514\n",
      "Validation Accuracy: 0.6755\n",
      "Epoch 95: Loss = 0.6379\n",
      "Validation Accuracy: 0.6737\n",
      "Epoch 96: Loss = 1.1911\n",
      "Validation Accuracy: 0.6746\n",
      "Epoch 97: Loss = 0.4468\n",
      "Validation Accuracy: 0.6746\n",
      "Epoch 98: Loss = 0.7690\n",
      "Validation Accuracy: 0.6737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:47<11:08, 83.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Loss = 0.4291\n",
      "Validation Accuracy: 0.6737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4361/4361 [00:00<00:00, 20899.49 examples/s]\n",
      "Map: 100%|██████████| 1091/1091 [00:00<00:00, 28523.25 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.6462\n",
      "Validation Accuracy: 0.2282\n",
      "Epoch 1: Loss = 1.6651\n",
      "Validation Accuracy: 0.2383\n",
      "Epoch 2: Loss = 1.5424\n",
      "Validation Accuracy: 0.2566\n",
      "Epoch 3: Loss = 1.7006\n",
      "Validation Accuracy: 0.2686\n",
      "Epoch 4: Loss = 1.6157\n",
      "Validation Accuracy: 0.2896\n",
      "Epoch 5: Loss = 1.5382\n",
      "Validation Accuracy: 0.3052\n",
      "Epoch 6: Loss = 1.5497\n",
      "Validation Accuracy: 0.3025\n",
      "Epoch 7: Loss = 1.4914\n",
      "Validation Accuracy: 0.3153\n",
      "Epoch 8: Loss = 1.5756\n",
      "Validation Accuracy: 0.3318\n",
      "Epoch 9: Loss = 1.6378\n",
      "Validation Accuracy: 0.3520\n",
      "Epoch 10: Loss = 1.5905\n",
      "Validation Accuracy: 0.3630\n",
      "Epoch 11: Loss = 1.5849\n",
      "Validation Accuracy: 0.3529\n",
      "Epoch 12: Loss = 1.4785\n",
      "Validation Accuracy: 0.3822\n",
      "Epoch 13: Loss = 1.4998\n",
      "Validation Accuracy: 0.3822\n",
      "Epoch 14: Loss = 1.5334\n",
      "Validation Accuracy: 0.3923\n",
      "Epoch 15: Loss = 1.4951\n",
      "Validation Accuracy: 0.4060\n",
      "Epoch 16: Loss = 1.6094\n",
      "Validation Accuracy: 0.4051\n",
      "Epoch 17: Loss = 1.4713\n",
      "Validation Accuracy: 0.4180\n",
      "Epoch 18: Loss = 1.6845\n",
      "Validation Accuracy: 0.4381\n",
      "Epoch 19: Loss = 1.5663\n",
      "Validation Accuracy: 0.4299\n",
      "Epoch 20: Loss = 1.5788\n",
      "Validation Accuracy: 0.4134\n",
      "Epoch 21: Loss = 1.4803\n",
      "Validation Accuracy: 0.4235\n",
      "Epoch 22: Loss = 1.4821\n",
      "Validation Accuracy: 0.4308\n",
      "Epoch 23: Loss = 1.4677\n",
      "Validation Accuracy: 0.4235\n",
      "Epoch 24: Loss = 1.4546\n",
      "Validation Accuracy: 0.4235\n",
      "Epoch 25: Loss = 1.5253\n",
      "Validation Accuracy: 0.4390\n",
      "Epoch 26: Loss = 1.4248\n",
      "Validation Accuracy: 0.4409\n",
      "Epoch 27: Loss = 1.4496\n",
      "Validation Accuracy: 0.4473\n",
      "Epoch 28: Loss = 1.3349\n",
      "Validation Accuracy: 0.4519\n",
      "Epoch 29: Loss = 1.9647\n",
      "Validation Accuracy: 0.4546\n",
      "Epoch 30: Loss = 1.4759\n",
      "Validation Accuracy: 0.4610\n",
      "Epoch 31: Loss = 1.2202\n",
      "Validation Accuracy: 0.4684\n",
      "Epoch 32: Loss = 1.4352\n",
      "Validation Accuracy: 0.4720\n",
      "Epoch 33: Loss = 1.1186\n",
      "Validation Accuracy: 0.4592\n",
      "Epoch 34: Loss = 1.5413\n",
      "Validation Accuracy: 0.4702\n",
      "Epoch 35: Loss = 1.3640\n",
      "Validation Accuracy: 0.4757\n",
      "Epoch 36: Loss = 1.3672\n",
      "Validation Accuracy: 0.4730\n",
      "Epoch 37: Loss = 1.2448\n",
      "Validation Accuracy: 0.4702\n",
      "Epoch 38: Loss = 1.3995\n",
      "Validation Accuracy: 0.4830\n",
      "Epoch 39: Loss = 1.3351\n",
      "Validation Accuracy: 0.4812\n",
      "Epoch 40: Loss = 1.2058\n",
      "Validation Accuracy: 0.4812\n",
      "Epoch 41: Loss = 1.0461\n",
      "Validation Accuracy: 0.4867\n",
      "Epoch 42: Loss = 1.0964\n",
      "Validation Accuracy: 0.4858\n",
      "Epoch 43: Loss = 1.2329\n",
      "Validation Accuracy: 0.4959\n",
      "Epoch 44: Loss = 1.4578\n",
      "Validation Accuracy: 0.5160\n",
      "Epoch 45: Loss = 1.5015\n",
      "Validation Accuracy: 0.5215\n",
      "Epoch 46: Loss = 1.1500\n",
      "Validation Accuracy: 0.5252\n",
      "Epoch 47: Loss = 1.4090\n",
      "Validation Accuracy: 0.5252\n",
      "Epoch 48: Loss = 1.2450\n",
      "Validation Accuracy: 0.5280\n",
      "Epoch 49: Loss = 1.3643\n",
      "Validation Accuracy: 0.5270\n",
      "Epoch 50: Loss = 1.0858\n",
      "Validation Accuracy: 0.5344\n",
      "Epoch 51: Loss = 1.1747\n",
      "Validation Accuracy: 0.5325\n",
      "Epoch 52: Loss = 1.4104\n",
      "Validation Accuracy: 0.5380\n",
      "Epoch 53: Loss = 1.0034\n",
      "Validation Accuracy: 0.5362\n",
      "Epoch 54: Loss = 1.1365\n",
      "Validation Accuracy: 0.5390\n",
      "Epoch 55: Loss = 1.3020\n",
      "Validation Accuracy: 0.5490\n",
      "Epoch 56: Loss = 1.2320\n",
      "Validation Accuracy: 0.5463\n",
      "Epoch 57: Loss = 1.2483\n",
      "Validation Accuracy: 0.5555\n",
      "Epoch 58: Loss = 1.4557\n",
      "Validation Accuracy: 0.5536\n",
      "Epoch 59: Loss = 1.0458\n",
      "Validation Accuracy: 0.5573\n",
      "Epoch 60: Loss = 0.9826\n",
      "Validation Accuracy: 0.5628\n",
      "Epoch 61: Loss = 1.2235\n",
      "Validation Accuracy: 0.5637\n",
      "Epoch 62: Loss = 1.2663\n",
      "Validation Accuracy: 0.5747\n",
      "Epoch 63: Loss = 0.8967\n",
      "Validation Accuracy: 0.5793\n",
      "Epoch 64: Loss = 0.9809\n",
      "Validation Accuracy: 0.5830\n",
      "Epoch 65: Loss = 0.9299\n",
      "Validation Accuracy: 0.5848\n",
      "Epoch 66: Loss = 0.9948\n",
      "Validation Accuracy: 0.5875\n",
      "Epoch 67: Loss = 1.0830\n",
      "Validation Accuracy: 0.5866\n",
      "Epoch 68: Loss = 0.8839\n",
      "Validation Accuracy: 0.5885\n",
      "Epoch 69: Loss = 0.9586\n",
      "Validation Accuracy: 0.5866\n",
      "Epoch 70: Loss = 1.2899\n",
      "Validation Accuracy: 0.5958\n",
      "Epoch 71: Loss = 1.2333\n",
      "Validation Accuracy: 0.5985\n",
      "Epoch 72: Loss = 0.9482\n",
      "Validation Accuracy: 0.6040\n",
      "Epoch 73: Loss = 1.2768\n",
      "Validation Accuracy: 0.6059\n",
      "Epoch 74: Loss = 1.2786\n",
      "Validation Accuracy: 0.6086\n",
      "Epoch 75: Loss = 1.2508\n",
      "Validation Accuracy: 0.6123\n",
      "Epoch 76: Loss = 0.8053\n",
      "Validation Accuracy: 0.6169\n",
      "Epoch 77: Loss = 0.9595\n",
      "Validation Accuracy: 0.6150\n",
      "Epoch 78: Loss = 1.1855\n",
      "Validation Accuracy: 0.6196\n",
      "Epoch 79: Loss = 0.6505\n",
      "Validation Accuracy: 0.6242\n",
      "Epoch 80: Loss = 0.8224\n",
      "Validation Accuracy: 0.6205\n",
      "Epoch 81: Loss = 0.9666\n",
      "Validation Accuracy: 0.6224\n",
      "Epoch 82: Loss = 0.7856\n",
      "Validation Accuracy: 0.6233\n",
      "Epoch 83: Loss = 0.6199\n",
      "Validation Accuracy: 0.6269\n",
      "Epoch 84: Loss = 0.7478\n",
      "Validation Accuracy: 0.6297\n",
      "Epoch 85: Loss = 1.0232\n",
      "Validation Accuracy: 0.6306\n",
      "Epoch 86: Loss = 1.1148\n",
      "Validation Accuracy: 0.6279\n",
      "Epoch 87: Loss = 0.9711\n",
      "Validation Accuracy: 0.6306\n",
      "Epoch 88: Loss = 0.5137\n",
      "Validation Accuracy: 0.6343\n",
      "Epoch 89: Loss = 0.8616\n",
      "Validation Accuracy: 0.6343\n",
      "Epoch 90: Loss = 0.7051\n",
      "Validation Accuracy: 0.6352\n",
      "Epoch 91: Loss = 0.5954\n",
      "Validation Accuracy: 0.6361\n",
      "Epoch 92: Loss = 0.6826\n",
      "Validation Accuracy: 0.6361\n",
      "Epoch 93: Loss = 1.0418\n",
      "Validation Accuracy: 0.6370\n",
      "Epoch 94: Loss = 0.5365\n",
      "Validation Accuracy: 0.6416\n",
      "Epoch 95: Loss = 0.8094\n",
      "Validation Accuracy: 0.6416\n",
      "Epoch 96: Loss = 0.5230\n",
      "Validation Accuracy: 0.6416\n",
      "Epoch 97: Loss = 1.2236\n",
      "Validation Accuracy: 0.6462\n",
      "Epoch 98: Loss = 1.2175\n",
      "Validation Accuracy: 0.6517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [04:11<09:48, 84.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Loss = 0.6836\n",
      "Validation Accuracy: 0.6544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4361/4361 [00:00<00:00, 21269.91 examples/s]\n",
      "Map: 100%|██████████| 1091/1091 [00:00<00:00, 29352.81 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.7208\n",
      "Validation Accuracy: 0.2163\n",
      "Epoch 1: Loss = 1.6855\n",
      "Validation Accuracy: 0.2392\n",
      "Epoch 2: Loss = 1.6839\n",
      "Validation Accuracy: 0.2411\n",
      "Epoch 3: Loss = 1.6504\n",
      "Validation Accuracy: 0.2383\n",
      "Epoch 4: Loss = 1.6931\n",
      "Validation Accuracy: 0.2676\n",
      "Epoch 5: Loss = 1.6630\n",
      "Validation Accuracy: 0.2896\n",
      "Epoch 6: Loss = 1.5480\n",
      "Validation Accuracy: 0.3089\n",
      "Epoch 7: Loss = 1.7233\n",
      "Validation Accuracy: 0.3236\n",
      "Epoch 8: Loss = 1.5959\n",
      "Validation Accuracy: 0.3199\n",
      "Epoch 9: Loss = 1.6136\n",
      "Validation Accuracy: 0.3566\n",
      "Epoch 10: Loss = 1.5561\n",
      "Validation Accuracy: 0.3776\n",
      "Epoch 11: Loss = 1.5232\n",
      "Validation Accuracy: 0.3721\n",
      "Epoch 12: Loss = 1.8174\n",
      "Validation Accuracy: 0.3758\n",
      "Epoch 13: Loss = 1.5397\n",
      "Validation Accuracy: 0.3896\n",
      "Epoch 14: Loss = 1.5687\n",
      "Validation Accuracy: 0.4143\n",
      "Epoch 15: Loss = 1.5335\n",
      "Validation Accuracy: 0.4271\n",
      "Epoch 16: Loss = 1.5324\n",
      "Validation Accuracy: 0.4115\n",
      "Epoch 17: Loss = 1.5080\n",
      "Validation Accuracy: 0.4262\n",
      "Epoch 18: Loss = 1.4888\n",
      "Validation Accuracy: 0.4427\n",
      "Epoch 19: Loss = 1.5131\n",
      "Validation Accuracy: 0.4629\n",
      "Epoch 20: Loss = 1.6187\n",
      "Validation Accuracy: 0.4720\n",
      "Epoch 21: Loss = 1.5551\n",
      "Validation Accuracy: 0.4766\n",
      "Epoch 22: Loss = 1.8571\n",
      "Validation Accuracy: 0.4840\n",
      "Epoch 23: Loss = 1.6920\n",
      "Validation Accuracy: 0.4830\n",
      "Epoch 24: Loss = 1.5261\n",
      "Validation Accuracy: 0.4840\n",
      "Epoch 25: Loss = 1.4063\n",
      "Validation Accuracy: 0.4940\n",
      "Epoch 26: Loss = 1.7949\n",
      "Validation Accuracy: 0.4940\n",
      "Epoch 27: Loss = 1.4436\n",
      "Validation Accuracy: 0.4922\n",
      "Epoch 28: Loss = 1.4398\n",
      "Validation Accuracy: 0.5032\n",
      "Epoch 29: Loss = 1.5167\n",
      "Validation Accuracy: 0.4821\n",
      "Epoch 30: Loss = 1.4499\n",
      "Validation Accuracy: 0.5087\n",
      "Epoch 31: Loss = 1.4914\n",
      "Validation Accuracy: 0.5096\n",
      "Epoch 32: Loss = 1.4602\n",
      "Validation Accuracy: 0.5041\n",
      "Epoch 33: Loss = 1.8466\n",
      "Validation Accuracy: 0.5133\n",
      "Epoch 34: Loss = 1.7434\n",
      "Validation Accuracy: 0.5124\n",
      "Epoch 35: Loss = 1.3770\n",
      "Validation Accuracy: 0.5197\n",
      "Epoch 36: Loss = 1.3962\n",
      "Validation Accuracy: 0.5206\n",
      "Epoch 37: Loss = 1.3985\n",
      "Validation Accuracy: 0.5206\n",
      "Epoch 38: Loss = 1.4258\n",
      "Validation Accuracy: 0.4959\n",
      "Epoch 39: Loss = 1.3075\n",
      "Validation Accuracy: 0.5170\n",
      "Epoch 40: Loss = 1.1240\n",
      "Validation Accuracy: 0.5225\n",
      "Epoch 41: Loss = 1.3740\n",
      "Validation Accuracy: 0.5179\n",
      "Epoch 42: Loss = 1.2521\n",
      "Validation Accuracy: 0.5160\n",
      "Epoch 43: Loss = 1.3206\n",
      "Validation Accuracy: 0.5252\n",
      "Epoch 44: Loss = 1.3558\n",
      "Validation Accuracy: 0.5362\n",
      "Epoch 45: Loss = 1.4145\n",
      "Validation Accuracy: 0.5417\n",
      "Epoch 46: Loss = 1.3867\n",
      "Validation Accuracy: 0.5500\n",
      "Epoch 47: Loss = 1.3731\n",
      "Validation Accuracy: 0.5472\n",
      "Epoch 48: Loss = 1.1688\n",
      "Validation Accuracy: 0.5600\n",
      "Epoch 49: Loss = 1.1703\n",
      "Validation Accuracy: 0.5481\n",
      "Epoch 50: Loss = 1.1261\n",
      "Validation Accuracy: 0.5500\n",
      "Epoch 51: Loss = 1.2144\n",
      "Validation Accuracy: 0.5555\n",
      "Epoch 52: Loss = 1.1010\n",
      "Validation Accuracy: 0.5710\n",
      "Epoch 53: Loss = 1.1313\n",
      "Validation Accuracy: 0.5729\n",
      "Epoch 54: Loss = 1.5255\n",
      "Validation Accuracy: 0.5802\n",
      "Epoch 55: Loss = 1.1677\n",
      "Validation Accuracy: 0.5875\n",
      "Epoch 56: Loss = 1.1591\n",
      "Validation Accuracy: 0.5885\n",
      "Epoch 57: Loss = 1.1547\n",
      "Validation Accuracy: 0.5949\n",
      "Epoch 58: Loss = 0.9862\n",
      "Validation Accuracy: 0.5894\n",
      "Epoch 59: Loss = 1.0692\n",
      "Validation Accuracy: 0.5940\n",
      "Epoch 60: Loss = 0.9282\n",
      "Validation Accuracy: 0.5903\n",
      "Epoch 61: Loss = 1.3757\n",
      "Validation Accuracy: 0.6132\n",
      "Epoch 62: Loss = 1.2875\n",
      "Validation Accuracy: 0.6059\n",
      "Epoch 63: Loss = 0.8937\n",
      "Validation Accuracy: 0.5985\n",
      "Epoch 64: Loss = 1.1897\n",
      "Validation Accuracy: 0.6178\n",
      "Epoch 65: Loss = 1.1654\n",
      "Validation Accuracy: 0.6187\n",
      "Epoch 66: Loss = 1.0986\n",
      "Validation Accuracy: 0.6205\n",
      "Epoch 67: Loss = 0.6554\n",
      "Validation Accuracy: 0.6196\n",
      "Epoch 68: Loss = 1.1684\n",
      "Validation Accuracy: 0.6224\n",
      "Epoch 69: Loss = 0.8003\n",
      "Validation Accuracy: 0.6178\n",
      "Epoch 70: Loss = 1.2052\n",
      "Validation Accuracy: 0.6214\n",
      "Epoch 71: Loss = 1.0267\n",
      "Validation Accuracy: 0.6205\n",
      "Epoch 72: Loss = 0.7021\n",
      "Validation Accuracy: 0.6214\n",
      "Epoch 73: Loss = 0.9921\n",
      "Validation Accuracy: 0.6334\n",
      "Epoch 74: Loss = 0.9828\n",
      "Validation Accuracy: 0.6334\n",
      "Epoch 75: Loss = 0.9507\n",
      "Validation Accuracy: 0.6389\n",
      "Epoch 76: Loss = 0.9236\n",
      "Validation Accuracy: 0.6370\n",
      "Epoch 77: Loss = 1.1528\n",
      "Validation Accuracy: 0.6352\n",
      "Epoch 78: Loss = 0.9411\n",
      "Validation Accuracy: 0.6508\n",
      "Epoch 79: Loss = 1.0471\n",
      "Validation Accuracy: 0.6379\n",
      "Epoch 80: Loss = 0.9729\n",
      "Validation Accuracy: 0.6434\n",
      "Epoch 81: Loss = 0.8522\n",
      "Validation Accuracy: 0.6453\n",
      "Epoch 82: Loss = 0.8454\n",
      "Validation Accuracy: 0.6544\n",
      "Epoch 83: Loss = 1.2594\n",
      "Validation Accuracy: 0.6544\n",
      "Epoch 84: Loss = 0.6862\n",
      "Validation Accuracy: 0.6563\n",
      "Epoch 85: Loss = 0.7405\n",
      "Validation Accuracy: 0.6535\n",
      "Epoch 86: Loss = 0.9510\n",
      "Validation Accuracy: 0.6590\n",
      "Epoch 87: Loss = 1.2501\n",
      "Validation Accuracy: 0.6535\n",
      "Epoch 88: Loss = 0.6088\n",
      "Validation Accuracy: 0.6645\n",
      "Epoch 89: Loss = 0.7678\n",
      "Validation Accuracy: 0.6691\n",
      "Epoch 90: Loss = 1.1303\n",
      "Validation Accuracy: 0.6664\n",
      "Epoch 91: Loss = 0.8053\n",
      "Validation Accuracy: 0.6709\n",
      "Epoch 92: Loss = 0.7082\n",
      "Validation Accuracy: 0.6719\n",
      "Epoch 93: Loss = 0.7283\n",
      "Validation Accuracy: 0.6774\n",
      "Epoch 94: Loss = 0.7009\n",
      "Validation Accuracy: 0.6810\n",
      "Epoch 95: Loss = 1.0220\n",
      "Validation Accuracy: 0.6783\n",
      "Epoch 96: Loss = 1.0086\n",
      "Validation Accuracy: 0.6819\n",
      "Epoch 97: Loss = 0.5969\n",
      "Validation Accuracy: 0.6792\n",
      "Epoch 98: Loss = 0.6525\n",
      "Validation Accuracy: 0.6865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [05:35<08:23, 83.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Loss = 0.5946\n",
      "Validation Accuracy: 0.6829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4361/4361 [00:00<00:00, 21314.45 examples/s]\n",
      "Map: 100%|██████████| 1091/1091 [00:00<00:00, 29766.96 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.7798\n",
      "Validation Accuracy: 0.2566\n",
      "Epoch 1: Loss = 1.7751\n",
      "Validation Accuracy: 0.2484\n",
      "Epoch 2: Loss = 1.6987\n",
      "Validation Accuracy: 0.2566\n",
      "Epoch 3: Loss = 1.5562\n",
      "Validation Accuracy: 0.2456\n",
      "Epoch 4: Loss = 1.5523\n",
      "Validation Accuracy: 0.2851\n",
      "Epoch 5: Loss = 1.8701\n",
      "Validation Accuracy: 0.2786\n",
      "Epoch 6: Loss = 1.6650\n",
      "Validation Accuracy: 0.2887\n",
      "Epoch 7: Loss = 1.5308\n",
      "Validation Accuracy: 0.3016\n",
      "Epoch 8: Loss = 1.7828\n",
      "Validation Accuracy: 0.3199\n",
      "Epoch 9: Loss = 1.5399\n",
      "Validation Accuracy: 0.3355\n",
      "Epoch 10: Loss = 1.5450\n",
      "Validation Accuracy: 0.3428\n",
      "Epoch 11: Loss = 1.5655\n",
      "Validation Accuracy: 0.3355\n",
      "Epoch 12: Loss = 1.5472\n",
      "Validation Accuracy: 0.3547\n",
      "Epoch 13: Loss = 1.5129\n",
      "Validation Accuracy: 0.3831\n",
      "Epoch 14: Loss = 1.6129\n",
      "Validation Accuracy: 0.3740\n",
      "Epoch 15: Loss = 1.5061\n",
      "Validation Accuracy: 0.3721\n",
      "Epoch 16: Loss = 1.8813\n",
      "Validation Accuracy: 0.3896\n",
      "Epoch 17: Loss = 1.5363\n",
      "Validation Accuracy: 0.3941\n",
      "Epoch 18: Loss = 1.5486\n",
      "Validation Accuracy: 0.4161\n",
      "Epoch 19: Loss = 1.5470\n",
      "Validation Accuracy: 0.4180\n",
      "Epoch 20: Loss = 1.5053\n",
      "Validation Accuracy: 0.4225\n",
      "Epoch 21: Loss = 1.4901\n",
      "Validation Accuracy: 0.4290\n",
      "Epoch 22: Loss = 1.4836\n",
      "Validation Accuracy: 0.4326\n",
      "Epoch 23: Loss = 1.3868\n",
      "Validation Accuracy: 0.4473\n",
      "Epoch 24: Loss = 1.5738\n",
      "Validation Accuracy: 0.4409\n",
      "Epoch 25: Loss = 2.1228\n",
      "Validation Accuracy: 0.4693\n",
      "Epoch 26: Loss = 1.6216\n",
      "Validation Accuracy: 0.4684\n",
      "Epoch 27: Loss = 1.5384\n",
      "Validation Accuracy: 0.4766\n",
      "Epoch 28: Loss = 1.3861\n",
      "Validation Accuracy: 0.4913\n",
      "Epoch 29: Loss = 1.4482\n",
      "Validation Accuracy: 0.4913\n",
      "Epoch 30: Loss = 1.4038\n",
      "Validation Accuracy: 0.4812\n",
      "Epoch 31: Loss = 1.4488\n",
      "Validation Accuracy: 0.4950\n",
      "Epoch 32: Loss = 1.4402\n",
      "Validation Accuracy: 0.5142\n",
      "Epoch 33: Loss = 1.4843\n",
      "Validation Accuracy: 0.5170\n",
      "Epoch 34: Loss = 1.3940\n",
      "Validation Accuracy: 0.5206\n",
      "Epoch 35: Loss = 1.1621\n",
      "Validation Accuracy: 0.5124\n",
      "Epoch 36: Loss = 1.3560\n",
      "Validation Accuracy: 0.5399\n",
      "Epoch 37: Loss = 1.3762\n",
      "Validation Accuracy: 0.5390\n",
      "Epoch 38: Loss = 1.4311\n",
      "Validation Accuracy: 0.5408\n",
      "Epoch 39: Loss = 1.0537\n",
      "Validation Accuracy: 0.5426\n",
      "Epoch 40: Loss = 1.2338\n",
      "Validation Accuracy: 0.5481\n",
      "Epoch 41: Loss = 1.9964\n",
      "Validation Accuracy: 0.5417\n",
      "Epoch 42: Loss = 1.2495\n",
      "Validation Accuracy: 0.5481\n",
      "Epoch 43: Loss = 1.0992\n",
      "Validation Accuracy: 0.5518\n",
      "Epoch 44: Loss = 1.0324\n",
      "Validation Accuracy: 0.5536\n",
      "Epoch 45: Loss = 0.8965\n",
      "Validation Accuracy: 0.5600\n",
      "Epoch 46: Loss = 1.3487\n",
      "Validation Accuracy: 0.5610\n",
      "Epoch 47: Loss = 2.0781\n",
      "Validation Accuracy: 0.5582\n",
      "Epoch 48: Loss = 1.1165\n",
      "Validation Accuracy: 0.5600\n",
      "Epoch 49: Loss = 1.1536\n",
      "Validation Accuracy: 0.5610\n",
      "Epoch 50: Loss = 1.1782\n",
      "Validation Accuracy: 0.5600\n",
      "Epoch 51: Loss = 1.7309\n",
      "Validation Accuracy: 0.5646\n",
      "Epoch 52: Loss = 0.8676\n",
      "Validation Accuracy: 0.5628\n",
      "Epoch 53: Loss = 1.2680\n",
      "Validation Accuracy: 0.5701\n",
      "Epoch 54: Loss = 1.1670\n",
      "Validation Accuracy: 0.5775\n",
      "Epoch 55: Loss = 1.1230\n",
      "Validation Accuracy: 0.5830\n",
      "Epoch 56: Loss = 1.1151\n",
      "Validation Accuracy: 0.5848\n",
      "Epoch 57: Loss = 1.1037\n",
      "Validation Accuracy: 0.5857\n",
      "Epoch 58: Loss = 1.3425\n",
      "Validation Accuracy: 0.5830\n",
      "Epoch 59: Loss = 0.8843\n",
      "Validation Accuracy: 0.5830\n",
      "Epoch 60: Loss = 1.3211\n",
      "Validation Accuracy: 0.5820\n",
      "Epoch 61: Loss = 1.1480\n",
      "Validation Accuracy: 0.5820\n",
      "Epoch 62: Loss = 0.7758\n",
      "Validation Accuracy: 0.5820\n",
      "Epoch 63: Loss = 1.0009\n",
      "Validation Accuracy: 0.5848\n",
      "Epoch 64: Loss = 0.7703\n",
      "Validation Accuracy: 0.5857\n",
      "Epoch 65: Loss = 1.3573\n",
      "Validation Accuracy: 0.5885\n",
      "Epoch 66: Loss = 0.7954\n",
      "Validation Accuracy: 0.5903\n",
      "Epoch 67: Loss = 0.6492\n",
      "Validation Accuracy: 0.5930\n",
      "Epoch 68: Loss = 0.7649\n",
      "Validation Accuracy: 0.5958\n",
      "Epoch 69: Loss = 0.6091\n",
      "Validation Accuracy: 0.5985\n",
      "Epoch 70: Loss = 1.0256\n",
      "Validation Accuracy: 0.6013\n",
      "Epoch 71: Loss = 1.2808\n",
      "Validation Accuracy: 0.6022\n",
      "Epoch 72: Loss = 1.8163\n",
      "Validation Accuracy: 0.6013\n",
      "Epoch 73: Loss = 0.9060\n",
      "Validation Accuracy: 0.6013\n",
      "Epoch 74: Loss = 1.2784\n",
      "Validation Accuracy: 0.6031\n",
      "Epoch 75: Loss = 1.0354\n",
      "Validation Accuracy: 0.6086\n",
      "Epoch 76: Loss = 1.2883\n",
      "Validation Accuracy: 0.6049\n",
      "Epoch 77: Loss = 0.8036\n",
      "Validation Accuracy: 0.6104\n",
      "Epoch 78: Loss = 1.0963\n",
      "Validation Accuracy: 0.6141\n",
      "Epoch 79: Loss = 0.9783\n",
      "Validation Accuracy: 0.6114\n",
      "Epoch 80: Loss = 1.2533\n",
      "Validation Accuracy: 0.6205\n",
      "Epoch 81: Loss = 0.9341\n",
      "Validation Accuracy: 0.6159\n",
      "Epoch 82: Loss = 1.6056\n",
      "Validation Accuracy: 0.6260\n",
      "Epoch 83: Loss = 1.1395\n",
      "Validation Accuracy: 0.6242\n",
      "Epoch 84: Loss = 0.9089\n",
      "Validation Accuracy: 0.6260\n",
      "Epoch 85: Loss = 0.8775\n",
      "Validation Accuracy: 0.6279\n",
      "Epoch 86: Loss = 0.6424\n",
      "Validation Accuracy: 0.6224\n",
      "Epoch 87: Loss = 1.5935\n",
      "Validation Accuracy: 0.6251\n",
      "Epoch 88: Loss = 0.5770\n",
      "Validation Accuracy: 0.6269\n",
      "Epoch 89: Loss = 0.8790\n",
      "Validation Accuracy: 0.6279\n",
      "Epoch 90: Loss = 0.7854\n",
      "Validation Accuracy: 0.6279\n",
      "Epoch 91: Loss = 0.9743\n",
      "Validation Accuracy: 0.6343\n",
      "Epoch 92: Loss = 1.0187\n",
      "Validation Accuracy: 0.6425\n",
      "Epoch 93: Loss = 0.7696\n",
      "Validation Accuracy: 0.6315\n",
      "Epoch 94: Loss = 0.7508\n",
      "Validation Accuracy: 0.6343\n",
      "Epoch 95: Loss = 0.8298\n",
      "Validation Accuracy: 0.6352\n",
      "Epoch 96: Loss = 1.0336\n",
      "Validation Accuracy: 0.6361\n",
      "Epoch 97: Loss = 0.6191\n",
      "Validation Accuracy: 0.6352\n",
      "Epoch 98: Loss = 0.9778\n",
      "Validation Accuracy: 0.6379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [06:56<06:53, 82.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Loss = 0.6495\n",
      "Validation Accuracy: 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4361/4361 [00:00<00:00, 21063.36 examples/s]\n",
      "Map: 100%|██████████| 1091/1091 [00:00<00:00, 28855.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.7816\n",
      "Validation Accuracy: 0.2264\n",
      "Epoch 1: Loss = 1.6733\n",
      "Validation Accuracy: 0.2126\n",
      "Epoch 2: Loss = 1.6025\n",
      "Validation Accuracy: 0.2282\n",
      "Epoch 3: Loss = 1.6534\n",
      "Validation Accuracy: 0.2530\n",
      "Epoch 4: Loss = 1.6500\n",
      "Validation Accuracy: 0.2658\n",
      "Epoch 5: Loss = 1.5728\n",
      "Validation Accuracy: 0.2832\n",
      "Epoch 6: Loss = 1.6828\n",
      "Validation Accuracy: 0.2970\n",
      "Epoch 7: Loss = 1.5721\n",
      "Validation Accuracy: 0.2961\n",
      "Epoch 8: Loss = 1.6565\n",
      "Validation Accuracy: 0.3226\n",
      "Epoch 9: Loss = 1.5283\n",
      "Validation Accuracy: 0.3556\n",
      "Epoch 10: Loss = 1.6148\n",
      "Validation Accuracy: 0.3740\n",
      "Epoch 11: Loss = 1.5240\n",
      "Validation Accuracy: 0.3822\n",
      "Epoch 12: Loss = 1.4804\n",
      "Validation Accuracy: 0.3914\n",
      "Epoch 13: Loss = 1.4978\n",
      "Validation Accuracy: 0.4042\n",
      "Epoch 14: Loss = 1.4497\n",
      "Validation Accuracy: 0.4088\n",
      "Epoch 15: Loss = 1.4074\n",
      "Validation Accuracy: 0.4290\n",
      "Epoch 16: Loss = 1.4482\n",
      "Validation Accuracy: 0.4280\n",
      "Epoch 17: Loss = 1.5286\n",
      "Validation Accuracy: 0.4510\n",
      "Epoch 18: Loss = 1.3442\n",
      "Validation Accuracy: 0.4638\n",
      "Epoch 19: Loss = 1.5242\n",
      "Validation Accuracy: 0.4610\n",
      "Epoch 20: Loss = 1.4001\n",
      "Validation Accuracy: 0.4665\n",
      "Epoch 21: Loss = 1.3326\n",
      "Validation Accuracy: 0.4684\n",
      "Epoch 22: Loss = 1.2263\n",
      "Validation Accuracy: 0.4638\n",
      "Epoch 23: Loss = 1.3306\n",
      "Validation Accuracy: 0.4684\n",
      "Epoch 24: Loss = 1.3896\n",
      "Validation Accuracy: 0.4684\n",
      "Epoch 25: Loss = 1.5591\n",
      "Validation Accuracy: 0.4638\n",
      "Epoch 26: Loss = 1.5452\n",
      "Validation Accuracy: 0.4638\n",
      "Epoch 27: Loss = 1.3452\n",
      "Validation Accuracy: 0.4638\n",
      "Epoch 28: Loss = 1.2768\n",
      "Validation Accuracy: 0.4601\n",
      "Epoch 29: Loss = 1.3602\n",
      "Validation Accuracy: 0.4647\n",
      "Epoch 30: Loss = 1.4775\n",
      "Validation Accuracy: 0.4720\n",
      "Epoch 31: Loss = 1.4035\n",
      "Validation Accuracy: 0.4739\n",
      "Epoch 32: Loss = 1.1047\n",
      "Validation Accuracy: 0.4730\n",
      "Epoch 33: Loss = 1.3925\n",
      "Validation Accuracy: 0.4757\n",
      "Epoch 34: Loss = 1.2266\n",
      "Validation Accuracy: 0.4748\n",
      "Epoch 35: Loss = 1.5828\n",
      "Validation Accuracy: 0.4775\n",
      "Epoch 36: Loss = 1.2802\n",
      "Validation Accuracy: 0.4785\n",
      "Epoch 37: Loss = 1.6123\n",
      "Validation Accuracy: 0.4794\n",
      "Epoch 38: Loss = 1.1539\n",
      "Validation Accuracy: 0.4794\n",
      "Epoch 39: Loss = 1.1124\n",
      "Validation Accuracy: 0.4812\n",
      "Epoch 40: Loss = 1.2881\n",
      "Validation Accuracy: 0.4840\n",
      "Epoch 41: Loss = 1.0614\n",
      "Validation Accuracy: 0.4812\n",
      "Epoch 42: Loss = 1.0728\n",
      "Validation Accuracy: 0.4858\n",
      "Epoch 43: Loss = 0.8701\n",
      "Validation Accuracy: 0.4885\n",
      "Epoch 44: Loss = 1.2861\n",
      "Validation Accuracy: 0.5050\n",
      "Epoch 45: Loss = 1.4068\n",
      "Validation Accuracy: 0.4885\n",
      "Epoch 46: Loss = 1.0662\n",
      "Validation Accuracy: 0.5069\n",
      "Epoch 47: Loss = 1.0620\n",
      "Validation Accuracy: 0.5151\n",
      "Epoch 48: Loss = 1.2371\n",
      "Validation Accuracy: 0.5170\n",
      "Epoch 49: Loss = 1.1949\n",
      "Validation Accuracy: 0.5206\n",
      "Epoch 50: Loss = 1.2732\n",
      "Validation Accuracy: 0.5261\n",
      "Epoch 51: Loss = 1.2693\n",
      "Validation Accuracy: 0.5252\n",
      "Epoch 52: Loss = 1.2082\n",
      "Validation Accuracy: 0.5325\n",
      "Epoch 53: Loss = 1.2190\n",
      "Validation Accuracy: 0.5362\n",
      "Epoch 54: Loss = 1.2777\n",
      "Validation Accuracy: 0.5445\n",
      "Epoch 55: Loss = 0.8351\n",
      "Validation Accuracy: 0.5490\n",
      "Epoch 56: Loss = 1.0465\n",
      "Validation Accuracy: 0.5509\n",
      "Epoch 57: Loss = 0.8230\n",
      "Validation Accuracy: 0.5591\n",
      "Epoch 58: Loss = 1.3441\n",
      "Validation Accuracy: 0.5637\n",
      "Epoch 59: Loss = 1.1736\n",
      "Validation Accuracy: 0.5747\n",
      "Epoch 60: Loss = 0.9605\n",
      "Validation Accuracy: 0.5894\n",
      "Epoch 61: Loss = 0.9553\n",
      "Validation Accuracy: 0.5885\n",
      "Epoch 62: Loss = 1.1524\n",
      "Validation Accuracy: 0.5921\n",
      "Epoch 63: Loss = 1.4300\n",
      "Validation Accuracy: 0.5894\n",
      "Epoch 64: Loss = 1.0420\n",
      "Validation Accuracy: 0.5930\n",
      "Epoch 65: Loss = 0.8366\n",
      "Validation Accuracy: 0.5940\n",
      "Epoch 66: Loss = 1.3611\n",
      "Validation Accuracy: 0.5921\n",
      "Epoch 67: Loss = 1.2246\n",
      "Validation Accuracy: 0.5958\n",
      "Epoch 68: Loss = 1.0309\n",
      "Validation Accuracy: 0.5949\n",
      "Epoch 69: Loss = 1.2679\n",
      "Validation Accuracy: 0.6013\n",
      "Epoch 70: Loss = 1.0780\n",
      "Validation Accuracy: 0.5940\n",
      "Epoch 71: Loss = 0.7745\n",
      "Validation Accuracy: 0.5949\n",
      "Epoch 72: Loss = 0.2824\n",
      "Validation Accuracy: 0.6004\n",
      "Epoch 73: Loss = 0.7755\n",
      "Validation Accuracy: 0.6049\n",
      "Epoch 74: Loss = 1.0927\n",
      "Validation Accuracy: 0.6059\n",
      "Epoch 75: Loss = 0.9488\n",
      "Validation Accuracy: 0.6031\n",
      "Epoch 76: Loss = 0.9228\n",
      "Validation Accuracy: 0.6086\n",
      "Epoch 77: Loss = 1.4216\n",
      "Validation Accuracy: 0.6077\n",
      "Epoch 78: Loss = 1.0798\n",
      "Validation Accuracy: 0.6150\n",
      "Epoch 79: Loss = 0.9383\n",
      "Validation Accuracy: 0.6141\n",
      "Epoch 80: Loss = 1.0959\n",
      "Validation Accuracy: 0.6205\n",
      "Epoch 81: Loss = 0.7205\n",
      "Validation Accuracy: 0.6196\n",
      "Epoch 82: Loss = 0.7962\n",
      "Validation Accuracy: 0.6169\n",
      "Epoch 83: Loss = 0.7890\n",
      "Validation Accuracy: 0.6159\n",
      "Epoch 84: Loss = 1.2947\n",
      "Validation Accuracy: 0.6334\n",
      "Epoch 85: Loss = 0.7700\n",
      "Validation Accuracy: 0.6425\n",
      "Epoch 86: Loss = 0.4889\n",
      "Validation Accuracy: 0.6563\n",
      "Epoch 87: Loss = 0.9143\n",
      "Validation Accuracy: 0.6636\n",
      "Epoch 88: Loss = 0.5107\n",
      "Validation Accuracy: 0.6691\n",
      "Epoch 89: Loss = 1.0258\n",
      "Validation Accuracy: 0.6691\n",
      "Epoch 90: Loss = 1.3581\n",
      "Validation Accuracy: 0.6737\n",
      "Epoch 91: Loss = 0.7949\n",
      "Validation Accuracy: 0.6792\n",
      "Epoch 92: Loss = 0.8030\n",
      "Validation Accuracy: 0.6755\n",
      "Epoch 93: Loss = 0.7221\n",
      "Validation Accuracy: 0.6801\n",
      "Epoch 94: Loss = 0.9287\n",
      "Validation Accuracy: 0.6819\n",
      "Epoch 95: Loss = 0.6586\n",
      "Validation Accuracy: 0.6810\n",
      "Epoch 96: Loss = 0.7162\n",
      "Validation Accuracy: 0.6874\n",
      "Epoch 97: Loss = 0.4849\n",
      "Validation Accuracy: 0.6948\n",
      "Epoch 98: Loss = 0.6639\n",
      "Validation Accuracy: 0.6994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [08:25<05:39, 84.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Loss = 0.4530\n",
      "Validation Accuracy: 0.6957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4361/4361 [00:00<00:00, 20909.05 examples/s]\n",
      "Map: 100%|██████████| 1091/1091 [00:00<00:00, 29349.04 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.7808\n",
      "Validation Accuracy: 0.2383\n",
      "Epoch 1: Loss = 1.6182\n",
      "Validation Accuracy: 0.2667\n",
      "Epoch 2: Loss = 1.5573\n",
      "Validation Accuracy: 0.2704\n",
      "Epoch 3: Loss = 1.8024\n",
      "Validation Accuracy: 0.3153\n",
      "Epoch 4: Loss = 1.5995\n",
      "Validation Accuracy: 0.3364\n",
      "Epoch 5: Loss = 1.5570\n",
      "Validation Accuracy: 0.3382\n",
      "Epoch 6: Loss = 1.5541\n",
      "Validation Accuracy: 0.3199\n",
      "Epoch 7: Loss = 1.5292\n",
      "Validation Accuracy: 0.3721\n",
      "Epoch 8: Loss = 1.5618\n",
      "Validation Accuracy: 0.3905\n",
      "Epoch 9: Loss = 1.5429\n",
      "Validation Accuracy: 0.3978\n",
      "Epoch 10: Loss = 1.8522\n",
      "Validation Accuracy: 0.3813\n",
      "Epoch 11: Loss = 1.5930\n",
      "Validation Accuracy: 0.3786\n",
      "Epoch 12: Loss = 1.5615\n",
      "Validation Accuracy: 0.3822\n",
      "Epoch 13: Loss = 1.5585\n",
      "Validation Accuracy: 0.3932\n",
      "Epoch 14: Loss = 1.4798\n",
      "Validation Accuracy: 0.3996\n",
      "Epoch 15: Loss = 1.5634\n",
      "Validation Accuracy: 0.4051\n",
      "Epoch 16: Loss = 1.5605\n",
      "Validation Accuracy: 0.4143\n",
      "Epoch 17: Loss = 1.5747\n",
      "Validation Accuracy: 0.4244\n",
      "Epoch 18: Loss = 1.5401\n",
      "Validation Accuracy: 0.4244\n",
      "Epoch 19: Loss = 1.5178\n",
      "Validation Accuracy: 0.4308\n",
      "Epoch 20: Loss = 1.5509\n",
      "Validation Accuracy: 0.4280\n",
      "Epoch 21: Loss = 1.4477\n",
      "Validation Accuracy: 0.4491\n",
      "Epoch 22: Loss = 1.4589\n",
      "Validation Accuracy: 0.4390\n",
      "Epoch 23: Loss = 1.5522\n",
      "Validation Accuracy: 0.4620\n",
      "Epoch 24: Loss = 1.4336\n",
      "Validation Accuracy: 0.4583\n",
      "Epoch 25: Loss = 1.4769\n",
      "Validation Accuracy: 0.4610\n",
      "Epoch 26: Loss = 1.5283\n",
      "Validation Accuracy: 0.4565\n",
      "Epoch 27: Loss = 1.4112\n",
      "Validation Accuracy: 0.4748\n",
      "Epoch 28: Loss = 1.4200\n",
      "Validation Accuracy: 0.4665\n",
      "Epoch 29: Loss = 1.4059\n",
      "Validation Accuracy: 0.4702\n",
      "Epoch 30: Loss = 1.4621\n",
      "Validation Accuracy: 0.4849\n",
      "Epoch 31: Loss = 1.3890\n",
      "Validation Accuracy: 0.4849\n",
      "Epoch 32: Loss = 1.4878\n",
      "Validation Accuracy: 0.5307\n",
      "Epoch 33: Loss = 1.4362\n",
      "Validation Accuracy: 0.5325\n",
      "Epoch 34: Loss = 1.4269\n",
      "Validation Accuracy: 0.5390\n",
      "Epoch 35: Loss = 1.3168\n",
      "Validation Accuracy: 0.5399\n",
      "Epoch 36: Loss = 1.4871\n",
      "Validation Accuracy: 0.5591\n",
      "Epoch 37: Loss = 1.4692\n",
      "Validation Accuracy: 0.5555\n",
      "Epoch 38: Loss = 1.3042\n",
      "Validation Accuracy: 0.5545\n",
      "Epoch 39: Loss = 1.1984\n",
      "Validation Accuracy: 0.5610\n",
      "Epoch 40: Loss = 1.3350\n",
      "Validation Accuracy: 0.5628\n",
      "Epoch 41: Loss = 1.2277\n",
      "Validation Accuracy: 0.5720\n",
      "Epoch 42: Loss = 1.4799\n",
      "Validation Accuracy: 0.5747\n",
      "Epoch 43: Loss = 1.1525\n",
      "Validation Accuracy: 0.5710\n",
      "Epoch 44: Loss = 1.1303\n",
      "Validation Accuracy: 0.5756\n",
      "Epoch 45: Loss = 1.2464\n",
      "Validation Accuracy: 0.5738\n",
      "Epoch 46: Loss = 1.0664\n",
      "Validation Accuracy: 0.5857\n",
      "Epoch 47: Loss = 1.2926\n",
      "Validation Accuracy: 0.5866\n",
      "Epoch 48: Loss = 1.2790\n",
      "Validation Accuracy: 0.5885\n",
      "Epoch 49: Loss = 1.0788\n",
      "Validation Accuracy: 0.5912\n",
      "Epoch 50: Loss = 1.1642\n",
      "Validation Accuracy: 0.5995\n",
      "Epoch 51: Loss = 0.8306\n",
      "Validation Accuracy: 0.6022\n",
      "Epoch 52: Loss = 1.2476\n",
      "Validation Accuracy: 0.6022\n",
      "Epoch 53: Loss = 1.2195\n",
      "Validation Accuracy: 0.6040\n",
      "Epoch 54: Loss = 1.0237\n",
      "Validation Accuracy: 0.6049\n",
      "Epoch 55: Loss = 1.1305\n",
      "Validation Accuracy: 0.6049\n",
      "Epoch 56: Loss = 1.0805\n",
      "Validation Accuracy: 0.6068\n",
      "Epoch 57: Loss = 1.2959\n",
      "Validation Accuracy: 0.6159\n",
      "Epoch 58: Loss = 1.2261\n",
      "Validation Accuracy: 0.6169\n",
      "Epoch 59: Loss = 1.2476\n",
      "Validation Accuracy: 0.6114\n",
      "Epoch 60: Loss = 0.8029\n",
      "Validation Accuracy: 0.6214\n",
      "Epoch 61: Loss = 1.1082\n",
      "Validation Accuracy: 0.6214\n",
      "Epoch 62: Loss = 0.9769\n",
      "Validation Accuracy: 0.6214\n",
      "Epoch 63: Loss = 1.1872\n",
      "Validation Accuracy: 0.6297\n",
      "Epoch 64: Loss = 0.9222\n",
      "Validation Accuracy: 0.6425\n",
      "Epoch 65: Loss = 1.1317\n",
      "Validation Accuracy: 0.6343\n",
      "Epoch 66: Loss = 0.9796\n",
      "Validation Accuracy: 0.6407\n",
      "Epoch 67: Loss = 1.1829\n",
      "Validation Accuracy: 0.6444\n",
      "Epoch 68: Loss = 0.8792\n",
      "Validation Accuracy: 0.6554\n",
      "Epoch 69: Loss = 0.8053\n",
      "Validation Accuracy: 0.6544\n",
      "Epoch 70: Loss = 0.6945\n",
      "Validation Accuracy: 0.6554\n",
      "Epoch 71: Loss = 0.7316\n",
      "Validation Accuracy: 0.6636\n",
      "Epoch 72: Loss = 0.7304\n",
      "Validation Accuracy: 0.6590\n",
      "Epoch 73: Loss = 0.9319\n",
      "Validation Accuracy: 0.6609\n",
      "Epoch 74: Loss = 1.1183\n",
      "Validation Accuracy: 0.6654\n",
      "Epoch 75: Loss = 0.9811\n",
      "Validation Accuracy: 0.6709\n",
      "Epoch 76: Loss = 0.7608\n",
      "Validation Accuracy: 0.6700\n",
      "Epoch 77: Loss = 0.6582\n",
      "Validation Accuracy: 0.6719\n",
      "Epoch 78: Loss = 0.9777\n",
      "Validation Accuracy: 0.6691\n",
      "Epoch 79: Loss = 0.4903\n",
      "Validation Accuracy: 0.6728\n",
      "Epoch 80: Loss = 0.7993\n",
      "Validation Accuracy: 0.6764\n",
      "Epoch 81: Loss = 0.7454\n",
      "Validation Accuracy: 0.6774\n",
      "Epoch 82: Loss = 0.6952\n",
      "Validation Accuracy: 0.6810\n",
      "Epoch 83: Loss = 0.9081\n",
      "Validation Accuracy: 0.6838\n",
      "Epoch 84: Loss = 1.0447\n",
      "Validation Accuracy: 0.6829\n",
      "Epoch 85: Loss = 0.8243\n",
      "Validation Accuracy: 0.6893\n",
      "Epoch 86: Loss = 0.7545\n",
      "Validation Accuracy: 0.6929\n",
      "Epoch 87: Loss = 0.7520\n",
      "Validation Accuracy: 0.6939\n",
      "Epoch 88: Loss = 0.5620\n",
      "Validation Accuracy: 0.6911\n",
      "Epoch 89: Loss = 1.0390\n",
      "Validation Accuracy: 0.6902\n",
      "Epoch 90: Loss = 1.1561\n",
      "Validation Accuracy: 0.6957\n",
      "Epoch 91: Loss = 0.4638\n",
      "Validation Accuracy: 0.6957\n",
      "Epoch 92: Loss = 0.5493\n",
      "Validation Accuracy: 0.6957\n",
      "Epoch 93: Loss = 0.2738\n",
      "Validation Accuracy: 0.6948\n",
      "Epoch 94: Loss = 0.4352\n",
      "Validation Accuracy: 0.7003\n",
      "Epoch 95: Loss = 0.8406\n",
      "Validation Accuracy: 0.6939\n",
      "Epoch 96: Loss = 0.5600\n",
      "Validation Accuracy: 0.7021\n",
      "Epoch 97: Loss = 0.5031\n",
      "Validation Accuracy: 0.6994\n",
      "Epoch 98: Loss = 0.4163\n",
      "Validation Accuracy: 0.7003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [09:48<04:13, 84.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Loss = 0.7923\n",
      "Validation Accuracy: 0.7030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4361/4361 [00:00<00:00, 21676.49 examples/s]\n",
      "Map: 100%|██████████| 1091/1091 [00:00<00:00, 29399.96 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.7049\n",
      "Validation Accuracy: 0.2090\n",
      "Epoch 1: Loss = 1.6896\n",
      "Validation Accuracy: 0.2383\n",
      "Epoch 2: Loss = 1.6345\n",
      "Validation Accuracy: 0.2502\n",
      "Epoch 3: Loss = 1.7098\n",
      "Validation Accuracy: 0.2649\n",
      "Epoch 4: Loss = 1.9563\n",
      "Validation Accuracy: 0.2557\n",
      "Epoch 5: Loss = 1.6184\n",
      "Validation Accuracy: 0.2750\n",
      "Epoch 6: Loss = 1.5892\n",
      "Validation Accuracy: 0.2640\n",
      "Epoch 7: Loss = 1.5716\n",
      "Validation Accuracy: 0.2896\n",
      "Epoch 8: Loss = 1.5814\n",
      "Validation Accuracy: 0.2942\n",
      "Epoch 9: Loss = 1.5283\n",
      "Validation Accuracy: 0.2915\n",
      "Epoch 10: Loss = 1.6124\n",
      "Validation Accuracy: 0.3135\n",
      "Epoch 11: Loss = 1.4637\n",
      "Validation Accuracy: 0.3190\n",
      "Epoch 12: Loss = 1.5113\n",
      "Validation Accuracy: 0.3208\n",
      "Epoch 13: Loss = 1.4767\n",
      "Validation Accuracy: 0.3025\n",
      "Epoch 14: Loss = 1.5541\n",
      "Validation Accuracy: 0.3346\n",
      "Epoch 15: Loss = 1.9166\n",
      "Validation Accuracy: 0.3382\n",
      "Epoch 16: Loss = 1.5692\n",
      "Validation Accuracy: 0.3428\n",
      "Epoch 17: Loss = 1.4523\n",
      "Validation Accuracy: 0.3465\n",
      "Epoch 18: Loss = 1.4688\n",
      "Validation Accuracy: 0.3456\n",
      "Epoch 19: Loss = 1.6004\n",
      "Validation Accuracy: 0.3511\n",
      "Epoch 20: Loss = 1.5553\n",
      "Validation Accuracy: 0.3621\n",
      "Epoch 21: Loss = 1.5070\n",
      "Validation Accuracy: 0.3584\n",
      "Epoch 22: Loss = 1.4747\n",
      "Validation Accuracy: 0.3740\n",
      "Epoch 23: Loss = 1.6481\n",
      "Validation Accuracy: 0.3776\n",
      "Epoch 24: Loss = 1.5376\n",
      "Validation Accuracy: 0.3804\n",
      "Epoch 25: Loss = 1.8775\n",
      "Validation Accuracy: 0.3905\n",
      "Epoch 26: Loss = 1.4779\n",
      "Validation Accuracy: 0.3923\n",
      "Epoch 27: Loss = 1.5030\n",
      "Validation Accuracy: 0.4005\n",
      "Epoch 28: Loss = 1.9729\n",
      "Validation Accuracy: 0.4189\n",
      "Epoch 29: Loss = 1.4787\n",
      "Validation Accuracy: 0.4198\n",
      "Epoch 30: Loss = 1.5882\n",
      "Validation Accuracy: 0.4207\n",
      "Epoch 31: Loss = 1.3891\n",
      "Validation Accuracy: 0.4317\n",
      "Epoch 32: Loss = 1.4359\n",
      "Validation Accuracy: 0.4326\n",
      "Epoch 33: Loss = 1.3268\n",
      "Validation Accuracy: 0.4170\n",
      "Epoch 34: Loss = 1.3908\n",
      "Validation Accuracy: 0.4445\n",
      "Epoch 35: Loss = 1.6194\n",
      "Validation Accuracy: 0.4510\n",
      "Epoch 36: Loss = 1.6561\n",
      "Validation Accuracy: 0.4629\n",
      "Epoch 37: Loss = 1.4842\n",
      "Validation Accuracy: 0.4326\n",
      "Epoch 38: Loss = 1.4940\n",
      "Validation Accuracy: 0.4647\n",
      "Epoch 39: Loss = 1.4921\n",
      "Validation Accuracy: 0.4510\n",
      "Epoch 40: Loss = 1.3800\n",
      "Validation Accuracy: 0.4720\n",
      "Epoch 41: Loss = 1.3758\n",
      "Validation Accuracy: 0.4748\n",
      "Epoch 42: Loss = 1.3588\n",
      "Validation Accuracy: 0.4785\n",
      "Epoch 43: Loss = 1.5610\n",
      "Validation Accuracy: 0.4656\n",
      "Epoch 44: Loss = 1.2352\n",
      "Validation Accuracy: 0.4739\n",
      "Epoch 45: Loss = 1.4019\n",
      "Validation Accuracy: 0.4711\n",
      "Epoch 46: Loss = 1.8029\n",
      "Validation Accuracy: 0.4730\n",
      "Epoch 47: Loss = 1.2169\n",
      "Validation Accuracy: 0.4876\n",
      "Epoch 48: Loss = 1.7124\n",
      "Validation Accuracy: 0.5005\n",
      "Epoch 49: Loss = 1.3085\n",
      "Validation Accuracy: 0.4968\n",
      "Epoch 50: Loss = 1.6004\n",
      "Validation Accuracy: 0.4913\n",
      "Epoch 51: Loss = 1.3810\n",
      "Validation Accuracy: 0.5050\n",
      "Epoch 52: Loss = 1.2269\n",
      "Validation Accuracy: 0.5032\n",
      "Epoch 53: Loss = 1.0734\n",
      "Validation Accuracy: 0.5005\n",
      "Epoch 54: Loss = 1.5725\n",
      "Validation Accuracy: 0.5225\n",
      "Epoch 55: Loss = 1.2702\n",
      "Validation Accuracy: 0.5179\n",
      "Epoch 56: Loss = 1.3191\n",
      "Validation Accuracy: 0.5261\n",
      "Epoch 57: Loss = 1.3721\n",
      "Validation Accuracy: 0.5234\n",
      "Epoch 58: Loss = 1.2026\n",
      "Validation Accuracy: 0.5362\n",
      "Epoch 59: Loss = 1.5701\n",
      "Validation Accuracy: 0.5280\n",
      "Epoch 60: Loss = 1.2180\n",
      "Validation Accuracy: 0.5353\n",
      "Epoch 61: Loss = 1.5288\n",
      "Validation Accuracy: 0.5344\n",
      "Epoch 62: Loss = 1.1435\n",
      "Validation Accuracy: 0.5472\n",
      "Epoch 63: Loss = 1.2340\n",
      "Validation Accuracy: 0.5390\n",
      "Epoch 64: Loss = 1.0921\n",
      "Validation Accuracy: 0.5463\n",
      "Epoch 65: Loss = 1.1480\n",
      "Validation Accuracy: 0.5463\n",
      "Epoch 66: Loss = 1.2292\n",
      "Validation Accuracy: 0.5610\n",
      "Epoch 67: Loss = 1.2654\n",
      "Validation Accuracy: 0.5481\n",
      "Epoch 68: Loss = 1.2123\n",
      "Validation Accuracy: 0.5674\n",
      "Epoch 69: Loss = 1.3436\n",
      "Validation Accuracy: 0.5527\n",
      "Epoch 70: Loss = 1.0357\n",
      "Validation Accuracy: 0.5573\n",
      "Epoch 71: Loss = 1.3505\n",
      "Validation Accuracy: 0.5637\n",
      "Epoch 72: Loss = 1.0357\n",
      "Validation Accuracy: 0.5591\n",
      "Epoch 73: Loss = 1.1337\n",
      "Validation Accuracy: 0.5610\n",
      "Epoch 74: Loss = 1.1847\n",
      "Validation Accuracy: 0.5683\n",
      "Epoch 75: Loss = 1.4662\n",
      "Validation Accuracy: 0.5729\n",
      "Epoch 76: Loss = 0.9760\n",
      "Validation Accuracy: 0.5793\n",
      "Epoch 77: Loss = 0.7642\n",
      "Validation Accuracy: 0.5848\n",
      "Epoch 78: Loss = 1.0532\n",
      "Validation Accuracy: 0.5784\n",
      "Epoch 79: Loss = 1.1758\n",
      "Validation Accuracy: 0.5848\n",
      "Epoch 80: Loss = 1.1637\n",
      "Validation Accuracy: 0.5903\n",
      "Epoch 81: Loss = 1.4517\n",
      "Validation Accuracy: 0.5985\n",
      "Epoch 82: Loss = 1.0475\n",
      "Validation Accuracy: 0.5885\n",
      "Epoch 83: Loss = 1.4622\n",
      "Validation Accuracy: 0.5912\n",
      "Epoch 84: Loss = 0.6951\n",
      "Validation Accuracy: 0.6031\n",
      "Epoch 85: Loss = 0.9642\n",
      "Validation Accuracy: 0.6031\n",
      "Epoch 86: Loss = 1.0457\n",
      "Validation Accuracy: 0.5995\n",
      "Epoch 87: Loss = 1.1109\n",
      "Validation Accuracy: 0.6104\n",
      "Epoch 88: Loss = 1.2832\n",
      "Validation Accuracy: 0.6114\n",
      "Epoch 89: Loss = 0.7518\n",
      "Validation Accuracy: 0.6114\n",
      "Epoch 90: Loss = 1.1979\n",
      "Validation Accuracy: 0.6132\n",
      "Epoch 91: Loss = 1.1440\n",
      "Validation Accuracy: 0.6187\n",
      "Epoch 92: Loss = 0.6736\n",
      "Validation Accuracy: 0.6205\n",
      "Epoch 93: Loss = 0.9658\n",
      "Validation Accuracy: 0.6104\n",
      "Epoch 94: Loss = 0.7472\n",
      "Validation Accuracy: 0.6279\n",
      "Epoch 95: Loss = 0.9692\n",
      "Validation Accuracy: 0.6214\n",
      "Epoch 96: Loss = 0.6618\n",
      "Validation Accuracy: 0.6178\n",
      "Epoch 97: Loss = 1.0170\n",
      "Validation Accuracy: 0.6242\n",
      "Epoch 98: Loss = 0.8384\n",
      "Validation Accuracy: 0.6297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [11:16<02:50, 85.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Loss = 1.1157\n",
      "Validation Accuracy: 0.6224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4361/4361 [00:00<00:00, 21056.26 examples/s]\n",
      "Map: 100%|██████████| 1091/1091 [00:00<00:00, 29230.37 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.7374\n",
      "Validation Accuracy: 0.1971\n",
      "Epoch 1: Loss = 1.6858\n",
      "Validation Accuracy: 0.2851\n",
      "Epoch 2: Loss = 1.7075\n",
      "Validation Accuracy: 0.2933\n",
      "Epoch 3: Loss = 1.6922\n",
      "Validation Accuracy: 0.2823\n",
      "Epoch 4: Loss = 1.6852\n",
      "Validation Accuracy: 0.2988\n",
      "Epoch 5: Loss = 1.7002\n",
      "Validation Accuracy: 0.3071\n",
      "Epoch 6: Loss = 1.5793\n",
      "Validation Accuracy: 0.3217\n",
      "Epoch 7: Loss = 1.5785\n",
      "Validation Accuracy: 0.3327\n",
      "Epoch 8: Loss = 1.6345\n",
      "Validation Accuracy: 0.3318\n",
      "Epoch 9: Loss = 1.8887\n",
      "Validation Accuracy: 0.3566\n",
      "Epoch 10: Loss = 1.8886\n",
      "Validation Accuracy: 0.3877\n",
      "Epoch 11: Loss = 1.5569\n",
      "Validation Accuracy: 0.4060\n",
      "Epoch 12: Loss = 1.4291\n",
      "Validation Accuracy: 0.4070\n",
      "Epoch 13: Loss = 1.4756\n",
      "Validation Accuracy: 0.4198\n",
      "Epoch 14: Loss = 1.4925\n",
      "Validation Accuracy: 0.4290\n",
      "Epoch 15: Loss = 1.5060\n",
      "Validation Accuracy: 0.4565\n",
      "Epoch 16: Loss = 1.4182\n",
      "Validation Accuracy: 0.4638\n",
      "Epoch 17: Loss = 1.5374\n",
      "Validation Accuracy: 0.4730\n",
      "Epoch 18: Loss = 1.3954\n",
      "Validation Accuracy: 0.4757\n",
      "Epoch 19: Loss = 1.6043\n",
      "Validation Accuracy: 0.4840\n",
      "Epoch 20: Loss = 1.3462\n",
      "Validation Accuracy: 0.5069\n",
      "Epoch 21: Loss = 1.4190\n",
      "Validation Accuracy: 0.5060\n",
      "Epoch 22: Loss = 1.3927\n",
      "Validation Accuracy: 0.5197\n",
      "Epoch 23: Loss = 1.4625\n",
      "Validation Accuracy: 0.5206\n",
      "Epoch 24: Loss = 1.4568\n",
      "Validation Accuracy: 0.5206\n",
      "Epoch 25: Loss = 1.6607\n",
      "Validation Accuracy: 0.5252\n",
      "Epoch 26: Loss = 1.3506\n",
      "Validation Accuracy: 0.5325\n",
      "Epoch 27: Loss = 1.7575\n",
      "Validation Accuracy: 0.5362\n",
      "Epoch 28: Loss = 1.3727\n",
      "Validation Accuracy: 0.5426\n",
      "Epoch 29: Loss = 1.3911\n",
      "Validation Accuracy: 0.5490\n",
      "Epoch 30: Loss = 1.1394\n",
      "Validation Accuracy: 0.5545\n",
      "Epoch 31: Loss = 1.6636\n",
      "Validation Accuracy: 0.5564\n",
      "Epoch 32: Loss = 1.1872\n",
      "Validation Accuracy: 0.5582\n",
      "Epoch 33: Loss = 1.2794\n",
      "Validation Accuracy: 0.5591\n",
      "Epoch 34: Loss = 1.2695\n",
      "Validation Accuracy: 0.5665\n",
      "Epoch 35: Loss = 1.4643\n",
      "Validation Accuracy: 0.5683\n",
      "Epoch 36: Loss = 1.4817\n",
      "Validation Accuracy: 0.5683\n",
      "Epoch 37: Loss = 1.3073\n",
      "Validation Accuracy: 0.5692\n",
      "Epoch 38: Loss = 1.2835\n",
      "Validation Accuracy: 0.5857\n",
      "Epoch 39: Loss = 1.1330\n",
      "Validation Accuracy: 0.5784\n",
      "Epoch 40: Loss = 1.0618\n",
      "Validation Accuracy: 0.5683\n",
      "Epoch 41: Loss = 1.3055\n",
      "Validation Accuracy: 0.5811\n",
      "Epoch 42: Loss = 1.0656\n",
      "Validation Accuracy: 0.5866\n",
      "Epoch 43: Loss = 1.1400\n",
      "Validation Accuracy: 0.5848\n",
      "Epoch 44: Loss = 1.1157\n",
      "Validation Accuracy: 0.5894\n",
      "Epoch 45: Loss = 1.2022\n",
      "Validation Accuracy: 0.5903\n",
      "Epoch 46: Loss = 1.4465\n",
      "Validation Accuracy: 0.5940\n",
      "Epoch 47: Loss = 0.9520\n",
      "Validation Accuracy: 0.5885\n",
      "Epoch 48: Loss = 1.1946\n",
      "Validation Accuracy: 0.5866\n",
      "Epoch 49: Loss = 1.0359\n",
      "Validation Accuracy: 0.5866\n",
      "Epoch 50: Loss = 0.9171\n",
      "Validation Accuracy: 0.5866\n",
      "Epoch 51: Loss = 1.0776\n",
      "Validation Accuracy: 0.5940\n",
      "Epoch 52: Loss = 1.0661\n",
      "Validation Accuracy: 0.5866\n",
      "Epoch 53: Loss = 1.0789\n",
      "Validation Accuracy: 0.5921\n",
      "Epoch 54: Loss = 1.0284\n",
      "Validation Accuracy: 0.5958\n",
      "Epoch 55: Loss = 1.4655\n",
      "Validation Accuracy: 0.5940\n",
      "Epoch 56: Loss = 0.8861\n",
      "Validation Accuracy: 0.6013\n",
      "Epoch 57: Loss = 1.2454\n",
      "Validation Accuracy: 0.5995\n",
      "Epoch 58: Loss = 1.1322\n",
      "Validation Accuracy: 0.6077\n",
      "Epoch 59: Loss = 1.0041\n",
      "Validation Accuracy: 0.6059\n",
      "Epoch 60: Loss = 1.2653\n",
      "Validation Accuracy: 0.6031\n",
      "Epoch 61: Loss = 1.0522\n",
      "Validation Accuracy: 0.6059\n",
      "Epoch 62: Loss = 1.0804\n",
      "Validation Accuracy: 0.6086\n",
      "Epoch 63: Loss = 1.4226\n",
      "Validation Accuracy: 0.6095\n",
      "Epoch 64: Loss = 1.0663\n",
      "Validation Accuracy: 0.6150\n",
      "Epoch 65: Loss = 1.1454\n",
      "Validation Accuracy: 0.6095\n",
      "Epoch 66: Loss = 1.1122\n",
      "Validation Accuracy: 0.6214\n",
      "Epoch 67: Loss = 1.2417\n",
      "Validation Accuracy: 0.6242\n",
      "Epoch 68: Loss = 0.7549\n",
      "Validation Accuracy: 0.6224\n",
      "Epoch 69: Loss = 0.8835\n",
      "Validation Accuracy: 0.6269\n",
      "Epoch 70: Loss = 1.1249\n",
      "Validation Accuracy: 0.6269\n",
      "Epoch 71: Loss = 0.6781\n",
      "Validation Accuracy: 0.6214\n",
      "Epoch 72: Loss = 1.0229\n",
      "Validation Accuracy: 0.6242\n",
      "Epoch 73: Loss = 1.2108\n",
      "Validation Accuracy: 0.6288\n",
      "Epoch 74: Loss = 1.1128\n",
      "Validation Accuracy: 0.6288\n",
      "Epoch 75: Loss = 0.8471\n",
      "Validation Accuracy: 0.6297\n",
      "Epoch 76: Loss = 1.1780\n",
      "Validation Accuracy: 0.6343\n",
      "Epoch 77: Loss = 0.6552\n",
      "Validation Accuracy: 0.6343\n",
      "Epoch 78: Loss = 1.0223\n",
      "Validation Accuracy: 0.6324\n",
      "Epoch 79: Loss = 1.3769\n",
      "Validation Accuracy: 0.6343\n",
      "Epoch 80: Loss = 1.2934\n",
      "Validation Accuracy: 0.6416\n",
      "Epoch 81: Loss = 0.7696\n",
      "Validation Accuracy: 0.6425\n",
      "Epoch 82: Loss = 0.9222\n",
      "Validation Accuracy: 0.6462\n",
      "Epoch 83: Loss = 0.7626\n",
      "Validation Accuracy: 0.6471\n",
      "Epoch 84: Loss = 0.5658\n",
      "Validation Accuracy: 0.6453\n",
      "Epoch 85: Loss = 0.6295\n",
      "Validation Accuracy: 0.6517\n",
      "Epoch 86: Loss = 1.3848\n",
      "Validation Accuracy: 0.6508\n",
      "Epoch 87: Loss = 1.0397\n",
      "Validation Accuracy: 0.6526\n",
      "Epoch 88: Loss = 0.5274\n",
      "Validation Accuracy: 0.6535\n",
      "Epoch 89: Loss = 0.8576\n",
      "Validation Accuracy: 0.6535\n",
      "Epoch 90: Loss = 0.5762\n",
      "Validation Accuracy: 0.6563\n",
      "Epoch 91: Loss = 0.5567\n",
      "Validation Accuracy: 0.6590\n",
      "Epoch 92: Loss = 1.0158\n",
      "Validation Accuracy: 0.6590\n",
      "Epoch 93: Loss = 0.6962\n",
      "Validation Accuracy: 0.6563\n",
      "Epoch 94: Loss = 1.0869\n",
      "Validation Accuracy: 0.6563\n",
      "Epoch 95: Loss = 0.9900\n",
      "Validation Accuracy: 0.6544\n",
      "Epoch 96: Loss = 0.6922\n",
      "Validation Accuracy: 0.6572\n",
      "Epoch 97: Loss = 0.5891\n",
      "Validation Accuracy: 0.6572\n",
      "Epoch 98: Loss = 0.8475\n",
      "Validation Accuracy: 0.6590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [12:39<01:24, 84.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Loss = 1.0366\n",
      "Validation Accuracy: 0.6572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4361/4361 [00:00<00:00, 14247.28 examples/s]\n",
      "Map: 100%|██████████| 1091/1091 [00:00<00:00, 28761.51 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.7043\n",
      "Validation Accuracy: 0.2172\n",
      "Epoch 1: Loss = 1.6582\n",
      "Validation Accuracy: 0.2383\n",
      "Epoch 2: Loss = 1.5740\n",
      "Validation Accuracy: 0.2475\n",
      "Epoch 3: Loss = 1.5948\n",
      "Validation Accuracy: 0.2612\n",
      "Epoch 4: Loss = 1.6615\n",
      "Validation Accuracy: 0.2658\n",
      "Epoch 5: Loss = 1.6161\n",
      "Validation Accuracy: 0.2896\n",
      "Epoch 6: Loss = 1.5994\n",
      "Validation Accuracy: 0.2988\n",
      "Epoch 7: Loss = 1.5307\n",
      "Validation Accuracy: 0.3153\n",
      "Epoch 8: Loss = 1.7370\n",
      "Validation Accuracy: 0.3272\n",
      "Epoch 9: Loss = 1.5476\n",
      "Validation Accuracy: 0.3291\n",
      "Epoch 10: Loss = 1.5414\n",
      "Validation Accuracy: 0.3538\n",
      "Epoch 11: Loss = 1.5868\n",
      "Validation Accuracy: 0.3639\n",
      "Epoch 12: Loss = 1.5491\n",
      "Validation Accuracy: 0.3529\n",
      "Epoch 13: Loss = 1.5368\n",
      "Validation Accuracy: 0.3621\n",
      "Epoch 14: Loss = 1.4726\n",
      "Validation Accuracy: 0.3483\n",
      "Epoch 15: Loss = 1.8771\n",
      "Validation Accuracy: 0.3547\n",
      "Epoch 16: Loss = 1.4814\n",
      "Validation Accuracy: 0.3877\n",
      "Epoch 17: Loss = 1.4972\n",
      "Validation Accuracy: 0.3841\n",
      "Epoch 18: Loss = 1.5134\n",
      "Validation Accuracy: 0.3941\n",
      "Epoch 19: Loss = 1.5110\n",
      "Validation Accuracy: 0.4042\n",
      "Epoch 20: Loss = 1.7898\n",
      "Validation Accuracy: 0.4106\n",
      "Epoch 21: Loss = 1.4359\n",
      "Validation Accuracy: 0.4510\n",
      "Epoch 22: Loss = 1.4194\n",
      "Validation Accuracy: 0.4794\n",
      "Epoch 23: Loss = 1.3841\n",
      "Validation Accuracy: 0.4858\n",
      "Epoch 24: Loss = 1.4897\n",
      "Validation Accuracy: 0.4940\n",
      "Epoch 25: Loss = 1.6176\n",
      "Validation Accuracy: 0.4950\n",
      "Epoch 26: Loss = 1.4222\n",
      "Validation Accuracy: 0.4895\n",
      "Epoch 27: Loss = 1.4964\n",
      "Validation Accuracy: 0.4885\n",
      "Epoch 28: Loss = 1.4542\n",
      "Validation Accuracy: 0.4968\n",
      "Epoch 29: Loss = 1.4144\n",
      "Validation Accuracy: 0.4986\n",
      "Epoch 30: Loss = 1.7410\n",
      "Validation Accuracy: 0.5014\n",
      "Epoch 31: Loss = 1.1714\n",
      "Validation Accuracy: 0.5032\n",
      "Epoch 32: Loss = 1.2978\n",
      "Validation Accuracy: 0.5060\n",
      "Epoch 33: Loss = 1.3372\n",
      "Validation Accuracy: 0.5096\n",
      "Epoch 34: Loss = 1.3047\n",
      "Validation Accuracy: 0.5151\n",
      "Epoch 35: Loss = 1.2204\n",
      "Validation Accuracy: 0.5087\n",
      "Epoch 36: Loss = 1.2657\n",
      "Validation Accuracy: 0.5206\n",
      "Epoch 37: Loss = 1.2098\n",
      "Validation Accuracy: 0.5215\n",
      "Epoch 38: Loss = 1.2282\n",
      "Validation Accuracy: 0.5197\n",
      "Epoch 39: Loss = 1.4499\n",
      "Validation Accuracy: 0.5280\n",
      "Epoch 40: Loss = 1.3943\n",
      "Validation Accuracy: 0.5270\n",
      "Epoch 41: Loss = 1.2130\n",
      "Validation Accuracy: 0.5353\n",
      "Epoch 42: Loss = 1.1817\n",
      "Validation Accuracy: 0.5362\n",
      "Epoch 43: Loss = 1.1762\n",
      "Validation Accuracy: 0.5261\n",
      "Epoch 44: Loss = 1.0142\n",
      "Validation Accuracy: 0.5371\n",
      "Epoch 45: Loss = 1.0793\n",
      "Validation Accuracy: 0.5408\n"
     ]
    }
   ],
   "source": [
    "samples = 10\n",
    "epochs = 100\n",
    "\n",
    "# Ajout : récupération de weights_fc\n",
    "weights_samples_1, weights_samples_2, weights_samples_fc = make_weight_list(samples, epochs)\n",
    "\n",
    "# Initialisation des tableaux de distance\n",
    "T = len(weights_samples_1[0])  # nombre d'epochs (ou itérations de suivi)\n",
    "dist_samples_1 = np.zeros((samples, T))\n",
    "dist_samples_2 = np.zeros((samples, T))\n",
    "dist_samples_fc = np.zeros((samples, T))\n",
    "\n",
    "# Calcul des similarités pour chaque run\n",
    "for i in tqdm(range(samples)):\n",
    "    dist_samples_1[i], dist_samples_2[i], dist_samples_fc[i] = make_distance_measure(\n",
    "        weights_samples_1[i],\n",
    "        weights_samples_2[i],\n",
    "        weights_samples_fc[i]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"realistic_dist_samples_1.npy\", dist_samples_1)\n",
    "np.save(\"realistic_dist_samples_2.npy\", dist_samples_2)\n",
    "np.save(\"realistic_dist_samples_fc.npy\", dist_samples_fc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAADuCAYAAAADWQ1tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIiElEQVR4nO3dd3xUVd748c/UZNITUkggEIokQAKBgDRpijSlroo8+1As+LCrK8gPXVhB0EXRdWFtoIKLgrjIrgq6iiUqTVpM6L2TkErqpE2m3PP7I2EkJIGUSSblvF+vec3Mveee+52b4cuZc889VyWEEEiSJElOo3Z2AJIkSS2dTMSSJElOJhOxJEmSk8lELEmS5GQyEUuSJDmZTMSSJElOJhOxJEmSk2mdHUBTpSgKKSkpeHp6olKpnB2OJEmNjBCC/Px8QkJCUKtv3eaVibiWUlJSCA0NdXYYkiQ1cklJSbRt2/aWZWQiriVPT0+g9CB7eXk5ORpJkhobo9FIaGioPVfcikzEtXS9O8LLy0smYkmSqlSdrkt5sk6SJMnJnJqId+3axbhx4wgJCUGlUrF169bbbrNz505iYmJwdXWlY8eOvPfeexXKfP7553Tr1g0XFxe6devGli1bKpRZvXo1HTp0wNXVlZiYGHbv3u2IjyRJklRjTk3EhYWF9OzZk3feeada5S9dusTYsWMZPHgwhw4d4i9/+QtPP/00n3/+ub3Mvn37mDJlCtOmTePIkSNMmzaNhx56iAMHDtjLbN68mblz5/L8889z6NAhBg8ezJgxY0hMTHT4Z5QkSbodVWOZBlOlUrFlyxYmTpxYZZk///nPfPXVV5w6dcq+bPbs2Rw5coR9+/YBMGXKFIxGI99++629zOjRo/H19WXTpk0A9OvXj969e/Puu+/ay3Tt2pWJEyeyfPnyasVrNBrx9vYmLy9P9hFLUgshhKj2cNWa5IgmdbJu3759jBw5styyUaNG8c9//hOLxYJOp2Pfvn0888wzFcq88cYbAJjNZhISEliwYEG5MiNHjmTv3r1V7rukpISSkhL7e6PRWMdPI0lSQxJCgNUKQoC9+SlK32N/Kn2tKJy4lMKRUxfI+ul7DqX/ygVtNlqVlh3/PuLw2JpUIk5LSyMoKKjcsqCgIKxWK5mZmQQHB1dZJi0tDYDMzExsNtsty1Rm+fLlvPjiiw76JJIkNSTLxctYTp5B5eYGKkClKmvZlrVurzdyVSpS8gpZGhuPcvI43XPP8GnHbLK8FAA0ChSVFOHm4ubQ+JpUIoaKQ0Gu96zcuLyyMjcvq06ZGy1cuJB58+bZ318fI2jacwC9u/utg663zp/6qbheeqvqqwesXqqtr1ibUL319Z1t0J5QwfUMK0wmDKPuQeWiryQkQaaxiKuZeaRk5vHW9zsJPHWccOMxProjn0KdwFvlxr1t72Jgx7646lwdHmmTSsStW7eu0GrNyMhAq9XSqlWrW5a53gL29/dHo9HcskxlXFxccHFxqbg8picu1ekjrrfLoOup3vqotr6OQb3U24SOK9TPMainv1djmhIgp6CYg+dT8PVwpX2gLwnHTpOSkc1wYxIf3JGPSSsIC+jIf5d+hq+Hb73F0aQS8YABA/jvf/9bbtkPP/xAnz590Ol09jKxsbHl+ol/+OEHBg4cCIBerycmJobY2FgmTZpkLxMbG8uECRNqHJPK1RWVq+P/h5Qkqf7YFIW4s1dRFMHAru0wuJTmj31HzxFQXEB8q/TSJOzXge+XfYW7621+9daRUxNxQUEB58+ft7+/dOkShw8fxs/Pj3bt2rFw4UKSk5PZsGEDUDpC4p133mHevHnMmjWLffv28c9//tM+GgJgzpw5DBkyhNdee40JEybw5Zdf8uOPP/LLL7/Yy8ybN49p06bRp08fBgwYwJo1a0hMTGT27NkN9+ElSXKa+HPJhPh50j6wfCs3MT2L0MLLbG9TemL+1cdfrvckDIBwou3btwtKO3LKPWbMmCGEEGLGjBli6NCh5bbZsWOH6NWrl9Dr9SIsLEy8++67Fer9z3/+I8LDw4VOpxMRERHi888/r1Bm1apVon379kKv14vevXuLnTt31ij2vLw8AYi8vLwabSdJknMduZgijl5KrbA8PStPRD38jIh4uLNoMz1M3Pv4oDrtpyY5otGMI25q5DhiSWp6kjPzSM3JJ6Zzm3J91SVmC5//FMfijYsp0V7Cy6xi1f1LGf776bXeV01yhJxrQpKkFsGmKJxIzKBHh+BySVgIwfb4E+gNJZRoLgHw+8u+DB51X4PFJhOxJEktwsnEDLq08Uev1ZRbfjE5A38fL7Yd/BJU0DVXRw/X1mha+TVYbDIRS5LU7NkUhfScAtoH+pRbbrFaOX4hiU7t/Nh54gcA7kpzxSswoEGH2TWp4WuSJEm1kVNQTIC3e7nkmm0s4Ns9RxjSK4IVW/5BidWEp9mFLkYdbn4N1xoG2SKWJKkFyCs04e3+23j/rLwC9hw5y4ShMRxJ3M9HP5YOke2ZFYAKFXqfhj0BLxOxJEnNntWmoCvrGxZC8OuJ8wzpFUFuUSbz/1k6AZivJoqIPA8A9L71dxVdZWQiliSp2bMqCtqyOymfupRMoJ837gY9T7//DAWmArq1jUQUdsFNsQLg4icTsSRJkkPZbApajZocYyGXU6/RKzyM5ze8QNzZeFx0LoyOnIYKNd5lAyr0DThiAmQiliSpBbDaFEDwy5EzDOnVlY3b/8UnO0qnRnj90Vc5dzkfAM/C0meXgFYNGp9MxJIkNXtWReFSSgZhwf5k5qfzwsbSucWf+93/Y1Sv0WTm5qNRbKitZV0T/v4NGp9MxJIkNXslJVYuXc2gW8e2/H3LP7DYLAyNHMxj987ih/3H0KjV+JpN9vLuoW0aND6ZiCVJatYysvM4cPwsd3bvxO4Tu9m670tUKhV/fuBZDp25zJ3dO5FfVIx3WSL2CglG7WZo0BhlIpYkqVkSQrD/2DmOX7hK147taOVj4PkNSwB4ZMQMwgI7U2QqIdjfh2s5RnzNRQC4+fk2+OT1MhFLktQsnbyUjFaj4e6+3XFz1bPkXy9xJeMKQT5BPDt5HofPXKZnl/ZkGwspNpnplZ0CgE+7tg0eq0zEkiQ1O/lFxVxKziCmawcALmec49+7/wPAqj+8yYWkLHRaLUF+3mz+YR+BpkICTYWg09Fh8KAGj1cmYkmSmhUhBHuOnGVgzy6oVCqy87P56Mc3EUIwccAEeoT14mpGNv0iO7Huyx289/mPtCvMBUDfvTt6N8feobk65KQ/kiQ1C8bCYuKOn6fYbCE0qBV+Xh78ejaeWW/PJtOYhburO8/97v9x4Pg5unVsw//7x0Z+jDsOwOCwQEg5i6FdqFNil4lYkqQmLzUzh7gTF+jXvTOt/X0ASM/N4I/vPk2mMYsA79b869kP8XMPYH9OMm9t+o7zV9PRajTMn3YfYbHfkAR4hrR2SvwyEUuS1KQZC4uJP3WJ0QN64qIvvRuzoijMeX8eqdmpdAgK47nJ/yBU7c2Hb37Ivv2HcSsq5G69hvF9uuITv4ek+EMAeLcJdspnkIlYkqQmy2K1sfPgKYb0irAnYYCN2//FLyf34Kp35e2JL3Dhtb/z9enTBADjb9j+2sUTXLvhfVBEZ8jIaqjw7WQiliSpSUm5lsORs1dQhMBitdG3W0e8PX47wXYp+QIvbXwJgNEXdZx+7Fn7uhy9K66+voR1DsPV1xu9txd6Ly90Xh5c1rgT0LkjJVm5Df2RZCKWJKlpEEJw6lIyiWmZjOgXiU5bMX3ZFBt/WDYDk2Kho1HLwBQdaldXkl08+C6gPf3uG8GL//dApRdspB65gLDZQNvwg8lkIpYkqdErMpWw69BpWrfyYWT/HqjVFZOlxWph9lt/5HhRMnobvDjyaXquGM83Jy+z7uNvAJj9uxG3vmrOakOlafi0KBOxJEmN2tWMbBJOXWRQz3D8fTwrLWO1WXn6/Wf4/siPaBV4JDuUYbOf4sjZK4QElc6kptVoCC4bUVEVYbVCJS3t+iYTsSRJjZIQgvhTFyksLmHsoOhKuyIAzFYzT7/3DF//ug2tSs2Mc+4M79sPk9lCUkY2gX4+AHh5GKpsDQshQKUCqxVV2S2VGpJMxJIkNRo2RSE7r4C8giKupGbSytuDYTHdqiyvKArPrH22NAlrtDxp6U5o3lUC+/dh39Fz9A4P4/C5JAC83KueUc1qU9CoVQirDTQNn4jlJc6SJDUKNkUhdv9RziWlYbZY6dmlPdHhYbfcZtnmV/hy/1do1Vr+GvW/hMZfBSC/fUd8Pd1pE+hHZl4BcJtErJTeSsly+iy2tAyHfabqki1iSZKczmorHQ/cpV0wHdsG3bZ8UUkRSz98gX/t+xyAKZc80O3/LwBtxowkVWi4L7w9ABk5RoByQ9xudv2edppAf9T+DXubJJCJWJIkJ0vPzmP/sXNEdW5HxzaB9uWK1UpJTi7F6RkUX8vCdC2TgqSrnLt4khfyfsSoKb2t0f2JbvRK1+DVMYzOUx8gLSKKPh3aoFKpMFtt5BUUA7duEVtspXd5FmYLKr2+fj9wJWQiliQJKD1hJRQFYVMQiq3sWUFYrZUst6FYbWXLbRXX22woViu2YhNWkwmbyYS1uPxzfq6RzPRMhKkYb52GC4VFnM4vwJKfj6WgAGtRcYUYzWrB293yMLrZALjPHMofxj9E+7Gj8O7SmfTsPC6fS6R1Kx9sNoUDZ5LQq0tP0Pl5e1T52W1lXRPCbEGl01VZrr7IRFxHO554Gveq/gcV1ahA3L6QqE5Ft6unOvtxULy3K+OQz1NaUTWqqftxcdzfyAH7qWa8pQnUhnJjQr2eMK22cgn1xvXOUlWvrEqtxqWVH4bAALR+PvxTd5rUgmz8DN58s/gLQtt0tJdVFIW44xe4t38U2flFJJxPplu7ILaVlAAQ6OtV5f7NFhs6rQbMZlQuLbBFvHr1al5//XVSU1Pp3r07b7zxBoMHD66y/KpVq3jnnXe4fPky7dq14/nnn2f69On29RaLheXLl7N+/XqSk5MJDw/ntddeY/To0fYyS5cu5cUXXyxXb1BQEGlpaTWOP/PgEYqccJZVkhqaSq1GpVGjUmtKnzWa316rr78vfVZrNKi0GrQGAxpXF2xaLSZFRYlKhW8rX3z8fNC7G9C4uqLzcEfn4YHO3R2dlyc6Dw/0Xh6lyzw9UGu1KIrCtBUz2XX8PGqVmnfnvFsuCQPsP36ekEA/TiRmUGy2MqhbGG4uOq6V9RFXNQYZoMRqw0WnRZgt0NJaxJs3b2bu3LmsXr2aQYMG8f777zNmzBhOnjxJu3btKpR/9913WbhwIWvXrqVv377ExcUxa9YsfH19GTduHACLFi1i48aNrF27loiICL7//nsmTZrE3r176dWrl72u7t278+OPP9rfa2qZTPstX4qnu3uV66t166vqFapGNbcpU539VKdIteq5XRkHfJ7qVXPbWBzzeapX5rYlHLQftUZzQ2IsnyTLvy5NoupKl2vKb1vD+7gVmcycuJhE6rVcAv286NkmkEBfr1rdD+6LvVvYeXw3Br2BVX94k0FdBwBgtli5ZizixKUUTl1OoX/UHXQM9CXA+7d/kxnZpYn41i1iKx6uehACVSVX7dU3lajWb5360a9fP3r37s27775rX9a1a1cmTpzI8uXLK5QfOHAggwYN4vXXX7cvmzt3LvHx8fzyyy8AhISE8Pzzz/Pkk0/ay0ycOBEPDw82btwIlLaIt27dyuHDh2sdu9FoxNvbm7y8PLy8qv4DS1JLYrHauJicwdWMLCxWG907tKVtkF+tb8YphODzvV+yaMNiCkwFPDH6Ke7r+zD5xSXYbAKdVg02G4kp6TxwT19cb+omtFit9J/5AmaLlW1v/pnQ1pWPiPj17FXuCPbDZe9+DKPurlWsN6tJjnBai9hsNpOQkMCCBQvKLR85ciR79+6tdJuSkhJcXV3LLTMYDMTFxWGxWNDpdFWWuZ6orzt37hwhISG4uLjQr18/XnnlFTp2LP9T5+Z9l5T1NUHpQZYkCQqLTZy6nEJyRjYqVLRt3YpuHUNxc3XBpihk5RdhswkUoWCxKVjLHharDXPZw1L2uN4qvJ62vzv4OZ/sKG2oRbWPZuqQ3xPg442nqwsajZprOUb2HDnLg/fcWW4azOvOXE7FbLHi5W6gbZBflZ/BWFSCR2EBtoCGH7oGTkzEmZmZ2Gw2goLKjxm8VV/tqFGj+OCDD5g4cSK9e/cmISGBdevWYbFYyMzMJDg4mFGjRrFy5UqGDBlCp06d+Omnn/jyyy+x3XAiol+/fmzYsIEuXbqQnp7OsmXLGDhwICdOnKBVq8r/EMuXL6/Qrwxw4Ewi7h6V9z056rdGtU4EVa+ixlRN9U48NSBHxOO4Y9PYKrq5WkG2sYCrqdewKYLQEH8C/fzQaTSUCBVJWUbUKjUatarsoUatVqHVqNFqNLi56NC5uaLXadBp1Oi1GnRaTbmW839++S0JzxwxnRemPo9eqy8Xw76j5xg9sGelSRhg6854AKLuaFdlq9xYZMJFr0HJyUXjhDHE0AhO1t18cIQQVR6wxYsXk5aWRv/+/RFCEBQUxMyZM/nb3/5m7+N98803mTVrFhEREahUKjp16sQjjzzChx9+aK9nzJgx9tdRUVEMGDCATp06sX79eubNm1fpvhcuXFhundFoJDQ0lJ4dQurcNVHLX20V63FMNQ4LyFHx1PZnbYV6HFKLYypSOSia6h4aRx3DwmITl1OucTE5g7a+XozqE46nW9Xjc2sr/lwCf/7wLwA8MfoxFj/8fLnPYLFaOXzmCu2C/XGtJAkLIdjw9S42/7APgKkjB1S6H2NRCftPJzGoW3vE4aOoW9qtkvz9/dFoNBVavxkZGRVaydcZDAbWrVvH+++/T3p6OsHBwaxZswZPT0/8/UtnWAoICGDr1q2YTCaysrIICQlhwYIFdOjQocpY3N3diYqK4ty5c1WWcXFxwcXFpcJyV70WV73T/z+TpHqTV1DEpeQMrmZk46rX0aFNIKMHRpcO96oHF1Iv8Nib/4fZamZU75EVkjDAjoRT+Ht7EtmpbaXxvrjmc2IPHAPgyYdGMrSS+SpMZiv7TycyqFt73F31FOcXoPKo+sR7fXJaBtHr9cTExBAbG8ukSZPsy2NjY5kwYcItt9XpdLRtW/oH+PTTT7n//vsrzE/q6upKmzZtsFgsfP755zz00ENV1ldSUsKpU6duOWxOkloKIQTXcoxcSc0kLSsXL3cDHdoEEnVHOzT1PKLg0IXDTF/5KDkFOXRv1423Z/+jQhLONhagUavpFRFWIe74kxd5fvVmUjNz0WrUzJk6hhn3DylXzmpTSLyWy4XULGLuaIO7q/56BaicNBTVqU25efPmMW3aNPr06cOAAQNYs2YNiYmJzJ49GyjtDkhOTmbDhg0AnD17lri4OPr160dOTg4rV67k+PHjrF+/3l7ngQMHSE5OJjo6muTkZJYuXYqiKDz33HP2MvPnz2fcuHG0a9eOjIwMli1bhtFoZMaMGQ17ACTJyRRFwVhYTE5+IbnGItJz8rBabfj7eNI+2J+Yrh0qnYS9PmTnZzPzH4+TU5BDzw492DBvHW4uFeeHOHTmMr3Df/uFm5VXwJbtv/LfXQlcTC69NCQ0qBV/e/p/iOwcai93JSOHi2k5AAT7eXJ3j05oNI1j3rNaJeIdO3YwbNiwOu98ypQpZGVl8dJLL5GamkpkZCTbtm2jffvSyTpSU1NJTEy0l7fZbKxYsYIzZ86g0+kYPnw4e/fuJSwszF7GZDKxaNEiLl68iIeHB2PHjuXjjz/Gx8fHXubq1atMnTqVzMxMAgIC6N+/P/v377fvV5KaI7PFSmZuPhk5RjJzjJjMFjRqNV7uBny83Alq5U33Tm3R65zTPnt586tk5WcR3jacfy/4F+6u5bsJhBCcT0rj9OUUrqZlcfpKKqcvJXMxOQOl7KSki07L/UN6M/9/78fD7bfRU9eT8ODuYWgbSfK9Ua3GEV//2f/II48wY8YMQkNDb79RMyPHEUuNlcVqJb/IRHZeAVl5BeQYC7ApAr1OSytvDwJ8vQjw9ar0JJezxJ9LYOKyBwB4+X/eoJVbKFm5+WTm5ZOckcOV1EwS0zIxmS2Vbt+9Y1umjBzAiH6RFU4e5hYWc/RSGgO7tr9lEi7+YTuGkcMd9pnqfRxxSkoKGzdu5KOPPmLp0qXcc889PPbYY0ycOBG9E2YukqTmTAiB2WLFZLZQYrZQYrFSYrZgKrFQUGyi0FSCqeS3BKXTavAwuOLn7UHHNoH4du2Atoq+T0VRsCmi7LnsYStdZrPZUBSBVVFQlNKxv9fL37yudBsFs8VKcYmF4hIzxSVmTGXPpQ8LxSZzaczFJRQWl2AsLCIn30iy5RtQg94axt/X7anyWKjVKtoG+hHePoTw9iFEhAUTHhZCkJ93lSND0nIKaBfgc8sk7OyhlHW+su7w4cOsW7eOTZs2oSgKv//973nsscfo2bOno2JslK7/bzdhznJ0Lq6VlqnOob1tidrUIW5+W/cJaao3H1DdvsyitJLqlavHOKoZRmkktyhX3WN2y3JlgahUKlQqFWp12fMN79UqFUJQLpHaE6ZiK0ucNyfT0vXOTkAKxRTq4rFq0lAJF9poxhPkG4i/j6f9EdTKm/at/blwNYP/GTOoRi35tJx8jl1Ou21/sDCbMe2NwzDsLkd8LKCBr6yLjo5mwYIF+Pn58eqrr7Ju3TpWr17NgAEDeO+99+jevXtdd9GonU1MRaOrOKxNkpo6tUqFWq1Gqym9GEOj0dgvztCo1Wg06t/Wl128odNpMbjoMbjqMeh1v712+e3h4eaKu8GF8+nHePvb5VgtJrQaLZue3cCArndWiENRFM4lpePhZqhREjYWlXD8SjrDojre9qScs6a/vK7WidhisfDll1+ybt06YmNj6dOnD++88w5Tp04lOzubP//5zzz44IOcPHnSkfE2Okuf+B1u7lXPc1qdgfS3naunWhPk1LXA7fdTvfloblPH7atwyGQ/jjhm1frb3XYfDfNZNBr1bwnyhqvY1GUJ88Z1muuJ9aZ15ZJuLSb5qYmfDv/MG+uWYbFZiO7Yk6X/s5g+d8RUKCeE4MudCXh7uDEspmu16hZCcC2vkIMXUrirW/ty451FiRnFaETJL0AUFKIUFCIKixA2G7oOzjtZX6uuiT/96U9s2rQJgP/93//l8ccfJzIyslyZxMREwsLCUBTFMZE2MvJknSTVzq7ju5mx8jEsNgv39R3D27PfKHfp8o1+PXkBTzcDEWEh1apbUQRxZ5PQqNVEhgXhqtOiZGZhvXIV27VMVC4uqH29Ubu7o/J0R+3hgcrNUC/jh+u9a+LkyZO8/fbb/O53v6vy5FxISAjbt2+vTfWSJDVTx6+c4Im3/4jFZmFsn9G8M/tNdNrKuwQyc/PJMRbSt1un29ZbbLZw9mom6bkF3BHSijBfd8xHjlGcmYUmwB9tu7boY3rWayu/LmrVIt61axcDBw5Eqy2fx61WK3v37mXIkCFVbNl8yBaxJNXMmatnefDVqWTnZ9M/oh+fzF+PSxXnVxRF4ZtfDnHPnZG4uVZexmZTyCksJi07n9ScfCLbt6a1rwcqlQrTzj1oO3dEE9Laacm33lvEw4cPJzU1lcDAwHLL8/LyGD58eLmZziRJknYe28UfVj+FsSifnh168OHctVUmYYDLKdcIbe1vT8Jmq438ohKMRSay8ovIKyxBrVbh62Eg0Nudru0C7ZdfC7MZYbagbRPcIJ/NEWqViKuaIS0rKwv3W9ytQpKklkUIwYc/rmfpJ39FEQp97+jDurlr8DRUnDrWbLFSWGKhoNjMTwmnibyjPTuOXbRPAO/t5oqnmwudQ1rh7eZaZUvXlpGJJrjyicMaqxol4smTJwOlZ4JnzpxZbjYym83G0aNHGThwoGMjlCSpURFCoAiBEKAIgaII+xhmi610HLPVplBsLuGd//6D/+wpPbF/T8+xzBo1j2OXc7HZskvruqFenVaDh6uezOw82gT40D0sGHcXXY3ngxCFhU6bRa22apSIvb29gdI/hKenJwbDb5cS6vV6+vfvz6xZsxwbYSN3KikDD8+Kt/0GHDJLuEMukqhzDA6opI6ROCIGxxwL509mf/0ikJsT4o3v7a8Vx8Rb7s4ZKhVqFeUuLNGWDYPTatRo1SpyCrNY9ulCTiSWTkX5p3FzmTVqFi46LXqtBq2m8uFxVpuNbVdTuX9wr1pPNqQUFqH1q/puHI1RjRLx9cnVw8LCmD9/vuyGAFp5uOHpWfvj0FhO4tb1hIYjPodDJkuvYxWO+HM0xMkh+5V1NyREVDcuV6G64X1DSjh/iLlrZpOem4GXmyevP/oa9/Udc/sNgfNJ6dzRrnWdZnwTBYWo3CvO2taY1aqPeMmSJY6Oo8kK9PXAy6vqCzokqSXZvOs/LFy/CLPVTHibLnww5306BIVVe/tzSWmMHlC36RGEyYTKUPm0A41VtRNx7969+emnn/D19aVXr163/F/24MGDDglOkqSm46MfN7Do49JG2qjeI3nziRV4GKrfSEnLzKWVl4dD7vzRWMcLV6XaiXjChAn2k3MTJ06sr3gkSWqCvo3/nsUblwLwx/tms+CBZ2vcvXD0fCIDe3SpUxzCagUn3WWjLqqdiK93R9hsNoYNG0aPHj3w9fWtt8AkSWoajlw6yp/en4sQgmnDf8/CB5+rcYvUWFiMRq0uN5l7bSh5RtTeTe8Cqxr3iGs0GkaNGkVubm49hCNJUlOSkpXCo2/MwmQ2MSxqKH+dtrRW3QLHziXSvWPFG4HWlJKdg9rXp871NLRanZqMiori4sWLjo5FkqQmpNBUyMw3Hic9N4PwtuG8++TbaDU1O/9vtdk4dSmZohIzrf196hyTNfEqmtZN62IOqGUifvnll5k/fz5ff/01qampGI3Gcg9Jkpo3s9XMH1b/iZOJp/D3asX6Zz6o9Gq5W1EUhR/2HyW/sJi7osPrFI+w2TDt2osmMAB1Exu6BrWc9OfGTvgbf4Zcv/S5Jcw1ISf9kVoqs9XMH1Y9xfcHY3HRufCfhZvo3alXjev59eQFvNwMhFdzisvKCCGwXUnCfOoM+m4RaNs3nvtn1vukP3J6S0lqmcxWM7PfeZIfDv2Ii86FdXPW1CoJGwuLuZZjpE/XjrWOxZaWgfnIcdSBARhGDHPqHTbqqlaJeOjQoY6OQ5KkRq7EUsLsd54k9vBPuOhc+HDuWoZEDq5xPUIIfjl8mkE9w2t8Yk/YbNjSMrCcPovK3Q2XIQNRN7GLNypTp3vWFRUVkZiYiNlsLre8R48edQpKkqTGpcRSwv+980d+PPwzLjoXPnrmAwZ3r92NNlMzc/H19MDbo+q+XCEEotiEkmdEGI3YMrMRBYWgVqMJaIVL/75Nsi+4KrVKxNeuXeORRx7h22+/rXR9S+gjlqSWwpFJWAjBkbNXGNIrHKWoGFFcjCgsQiksQhQVoRjzwWIBQGUwoPb2QuXlib5Hd1Qe7k3uirnqqlUinjt3Ljk5Oezfv5/hw4ezZcsW0tPTWbZsGStWrHB0jJIkOUl+cT5PvP1Hdp/4BVe9Kx/+cTWD2kVjy84FmxVhsYLFgrDawFr2bLEgrNbSq9wsZWWsVgDOZObhbbWiLsrF7OqCymBA5e6G2t0NVUAr1J6eqFwqv/1ac1arRPzzzz/z5Zdf0rdvX9RqNe3bt+fee+/Fy8uL5cuXc9999zk6zkar5MhxSjxqOelPXadUbBRzQzaGz1DXGJy8f0DcLghRth+hgCJAEQihlC0ToJQtd6D0ohwe3/4PTudexaDR8/6wOfTNd8F8/BQqrQa0OlRaTelJMp0WlYsLKg8dKp0WtFpU2rLnsvd5BUUkHznLmIE96zS7WnNUq0RcWFhov02Sn58f165do0uXLkRFRbW4CX+0bYLRet5q/KST52V0yPyUdQ7CqZuDAyaBqfP2ddu8dI5LdWkcKhUqtQpUarj+rALUlc/xWxuX068w9W//S1LuVQK8/fnomX/Ss0Ptz/3YFIXdh04zrE83mYQrUatEHB4ezpkzZwgLCyM6Opr333+fsLAw3nvvPYKDm859ohxB498KjRxHLDUjF1Iv8NCrvyc9N52woDD+9ewG2gXUbXxu3PELdOvYFk83w+0Lt0C17iNOTU0FSicDGjVqFJ988gl6vZ6PPvrIkfFJktSATiWd5n9en8a1vEzC23Rh03MbCfQJqFOdSWlZmMxmOrVtepceN5RaXVl3s6KiIk6fPk27du3w9/d3RFyNnryyTmpu9p7az2NvPkF+cT7d2nVl07Mf08qrVZ3qLC4x88P+o4wd1Msh8ww3JTXJEQ7prHFzc6N37961SsKrV6+mQ4cOuLq6EhMTw+7du29ZftWqVXTt2hWDwUB4eDgbNmwot95isfDSSy/RqVMnXF1d6dmzJ999912d9ytJzVWhqZCln/yVh1/7PfnF+dzZpQ//XrCpzkm4yFRC7P5jDOoZ3uKScE1Vu2ti3rx51a505cqV1Sq3efNm5s6dy+rVqxk0aBDvv/8+Y8aM4eTJk7Rr165C+XfffZeFCxeydu1a+vbtS1xcHLNmzcLX15dx48YBsGjRIjZu3MjatWuJiIjg+++/Z9KkSezdu5devXrVar+S1Fz9cDCWRR8vJSU7BYDJAyfy2iPLMejrdrWaEIKffz3B4F4R+HrJe1veTrW7JoYPH169ClUqfv7552qV7devH7179+bdd9+1L+vatSsTJ05k+fLlFcoPHDiQQYMG8frrr9uXzZ07l/j4eH755RcAQkJCeP7553nyySftZSZOnIiHhwcbN26s1X4rI7smpKYs05jJwvWL+Ta+9Ndiu4BQXp7+V4b3cMz0BScuJCEERHZuPJPwNLR6mfTH0RP9mM1mEhISWLBgQbnlI0eOZO/evZVuU1JSgqtr+f+pDQYDcXFxWCwWdDpdlWWuJ+ra7Pf6vktKSuzv5XSfUlMVe+hH5v9zAVn5WWg1Wv5v9CzmTvgTBhfHjGhIy8wlMS2LUQPkVAfV5bQBfZmZmdhsNoKCyp9JDQoKIi0trdJtRo0axQcffEBCQgJCCOLj41m3bh0Wi4XMzEx7mZUrV3Lu3DkURSE2NpYvv/zSPsqjNvsFWL58Od7e3vZHaGjL/Z9eappyC/P4fx88xyNvzCIrP4uItuFsW/olCx96zmFJOMdYSNyJC9xzZ6QcL1wD1W4RT548mY8++ggvLy8mT558y7JffPFFtQO4eQD69TmNK7N48WLS0tLo378/QgiCgoKYOXMmf/vb39CU3TDwzTffZNasWURERKBSqejUqROPPPIIH374Ya33C7Bw4cJy/eRGo1EmY6nJ+P7gDyz8aBEZeddQqVTMGvUoz/3uWVz1Lg7bx/VZ1e65szt6XZ3mE2txqn20vL297YnK29u7zjv29/dHo9FUaIVmZGRUaK1eZzAYWLduHe+//z7p6ekEBwezZs0aPD097SM2AgIC2Lp1KyaTiaysLEJCQliwYAEdOnSo9X4BXFxc7HexlqSmIsuYxeKNS/nqwNcAdAruyN8ffY2+Xfo4fF9X07Np3coH92YwLWVDq3YivrFFeXPrsjb0ej0xMTHExsYyadIk+/LY2FgmTJhwy211Oh1t25beaPDTTz/l/vvvr/AzyNXVlTZt2mCxWPj888956KGH6rxfSWoqhBB8deBrFm9cSnZ+Nhq1htljnuCZiXMc2gq+0bELiQzv071e6m7unPr7Yd68eUybNo0+ffowYMAA1qxZQ2JiIrNnzwZKuwOSk5PtY4XPnj1LXFwc/fr1Iycnh5UrV3L8+HHWr19vr/PAgQMkJycTHR1NcnIyS5cuRVEUnnvuuWrvV5KaspSsFBZ9vIQfDv0IQNfQCFY89jd6dIiqt32mZ+fh6WbA0AJnTnOEWiXirKwsXnjhBbZv305GRgaKopRbn52dXa16pkyZQlZWFi+99BKpqalERkaybds22rdvD0BqaiqJiYn28jabjRUrVnDmzBl0Oh3Dhw9n7969hIWF2cuYTCYWLVrExYsX8fDwYOzYsXz88cf4+PhUe7+S1BRlGbNYF/sRa79fR1FJETqNjqfHP8WT989Gr63fBHno9CXuio6o1300Z7W6xHnMmDFcuHCBxx57jKCgoAonuWbMmOGwABurljKOOCcnhw0bNhAfH4+7uzuTJ09m5MiRzg5LusHZ5HNs+Hkjn+76NyazCYC+d/ThlRl/pWto/SfHlGs5XE65xsCeXep9X01Jvd889JdffuGXX36hZ8+etQpQahq2bt3K8uXLeeWVV/jjH//IkSNH6Nu3L4cPH5Z/eyfLKzTy37iv+ffuzzh44ZB9eY+wKJ68/w+M7TO6Qe5mIYTg4OlL3HNnZL3vqzmrVSKOiIiguLjY0bFIjUh+fj7Tp0/n2LFj9i6b3NxcgoKCaN26tZOja5msNis7j+/m8z1f8P3BHyixlN4rUqPWMCL6bmbcM43B3e9q0NsJXUnNJMjPW/YN11GtEvHq1atZsGABL7zwApGRkehuuo11c/6p3lKkp6eTn59Penq6PRGPGDHilhe9SI4nhOBk4ik+2/MFW/ZtJdOYZV8X3jacKYMfYNKACQR4122qytrGdvRcImMGyV9HdVWrROzj40NeXh533313ueXXL4qQNw+tSAhBcYmlwfdrcNHVqoXUqVMnRowYwZAhQ5g9ezZPPfUUnTt3BmDSpEns2LGDe+65h88++8zRIbd4QgjOJJ9l26/f8U38t5y5esa+rpVnKyYOGM/vBk4iKizSqTfTPJ+UTrvWrdBp5cUbdVWrk3V33nknWq2WOXPmVHqybuhQx0wc0pjV9GRdkclMvxmLGiCy8g6sX4aba+1+NprNZv7+97/z5ptvkpWVxeLFi1myZAnbt2+noKCA9evXy0TsAEIIkjKvEn8ugfhzCfxycg8X0y7Z17vo9NwbPYIH7prM0Mgh6LS6W9TWMGyKwte7D3LfXb3QauQUl5Wp95N1x48f59ChQ4SHh9cqQKlp0Ov1/OUvf+Gpp55i6tSpLF26lAkTJjB8+HB27Njh7PCaLLPVzLHLJ0g4n8Cv5xJIOJdARt61cmVcdHqGRg5hTJ/R3NtrBD7udb+a1ZFOXUymS7tgmYQdpFaJuE+fPiQlJclEXAMGFx0H1i9zyn5r4rPPPmP8+PHo9b+1or28vBg6dCjffvstbm5ujg6x2TJbzSRmJHEp/RIX0y5xKf0yZ66e5ejlo/YTbdfpNDqiwiLpc0dv+tzRhyHd78LDUMu7g9ezIpOZSykZ3HdXL2eH0mzUKhH/6U9/Ys6cOTz77LNERUVVOFnXo4ec/u5mKpWq1l0EDSkiIoIFCxbw6quv2pPxmTNnWLVqFS+//DJdusixojcqKC7galYyyZnJXLmWyKX0y1xKu8yltEskZV5FEUql2/l5+tH3jhhiOvemzx0x9AjrUW+XHjvavmNn6RfZWc6u5kC1SsRTpkwB4NFHH7UvU6lU8mRdMxAZGcnQoUO577770Ol0aDQaNBoNmzdvpn///s4Or0EpikJ2QTbpORkkZyWTlHm17DmZq9eucjUrmZyCnFvW4e7qToegMDq27lD23JFenaLpEBTm1BNttXU1Ixu9VkugX+PqKmnqapWIL126dPtCUpM1YcKEZjsBksVqIbcwl9zCPHILcskpyCGnIJeMvAzSctJJz80gPTed9JwMMvIysNqst63T292bUP+2tPVvS4egsN8Sb+sOBHoHNMmEW5kSs4WEUxcZMzDa2aE0O7VKxHJOhpZt1KhRHDx4kMLCQtq2bcuWLVvo27evw/djsVowWUyYzCaKzaXPJrMJk8VEcUlx2boSis3FFBQXkF9cQEFxfumz6fr7AvKL8ykwFZBbkEeBqaBGMahUKlp5+tGmVRvatAqxJ9y2/m3sz54GT4d/9sZGCMHuQ6fp172znGu4HlR7+NpXX33FmDFj0Ol0fPXVV7csO378eIcE15hdH5qSmpFaYWjKrQ5pVesENd+mdB0owoaiKChCwVb2LK6/LntvfxYKimJDEQJFUbCVvS4tbysrI0rLKDe8LtvWarNhtVmx2CxYbVasNitmq7lsmRWr1VL6XFbGYrWUK3+9TImlxJ5ISxNtsT3pXk+uNqV+urhUKhVebl74uPvg4+6Nj4cPQd6BBPkGEuQTVPrwDaS1TxAB3gGNYriYs124mk52XgF9u3dydihNRk2Gr1U7EavVatLS0ggMDLxlJ31L6SO+fpCDH26HWi9PWtQ3V70rrjpXXPWuGPSlz6WvDbjqXfE0eOJp8MDD4IGna9mzwbPs2QN3V3d83H3w9fDBy80LjVoOu6qu62OGxw7qhU4rj1t11cs44hunurx52kupcVCpVKhVajRqTbnXarUK1fXXZctVN6xTq9Sob1hn316tRqPSoFarUalUaNQaNGo1Wo0OnUaLVqNDq9GWvtZeX6ZFr9XdsK6qMnp7Ev0tqd6YbG9Yp3NpNv2sTVHc8QtEdQqVSbge1aiz58CBA2RnZzNmzBj7sg0bNrBkyRIKCwuZOHEib7/9dou6pdCht+Iq/9/uFolDReXrbpVrbpWIShOsWiYryeGSM7Ixmc10bFv1bcSkuqtRIl66dCnDhg2zJ+Jjx47x2GOPMXPmTLp27crrr79OSEgIS5curY9YGyWDi8Fhd8CVpMbEYrUSL0dJNIgadW4ePnyYe+65x/7+008/pV+/fqxdu5Z58+bx1ltv8e9//9vhQUqS1PD2HztP7/AOcpREA6hRIs7JySl3p+OdO3cyevRo+/u+ffuSlJTkuOgkSXKK1MwcrDYboa1bOTuUFqFGiTgoKMh+MYfZbObgwYMMGDDAvj4/P7/C5c6SJDUtiqLw64mLDOghL2dvKDVKxKNHj2bBggXs3r2bhQsX4ubmxuDBg+3rjx49SqdOcpyhJDVlpy+n0LFNIK562ahqKDVKxMuWLUOj0TB06FDWrl3L2rVry83StW7dOnljSUlqwswWK+eT0unWsY2zQ2lRajUxfF5eHh4eHmhumos0OzsbDw+Pcsm5uWopd3GWWpZdh07RsU0QbQP9nB1Kk1fvE8N7e1c+85Kfn/zjSVJTdfx8EnqtViZhJ5DjUqRbysnJYcOGDcTHx+Pu7s7kyZNl91MzdPFqOhk5Rob36ebsUFokOUmCVKWtW7cyevRoIiMjWbduHY8//jijRo3iyJEjzg5NcqDUzBzOJqYyNKarvDrTSWSLWKpUfn4+06dP59ixY/ZpT3NzcwkKCqJ169ZOjk5ylGxjAfEnLzJ6YE808o4bTiMTcQMRQmArNjX4fjUG11q1ctLT08nPzyc9Pd2eiEeMGEFaWpqjQ5ScJL+omN2HTnNvvx7otDIVOJM8+g3EVmzis5jBty/oYA8k7EbrVvO5MDp16sSIESMYMmQIs2fP5qmnnqJz584kJSUxbdo0MjIy0Gq1LF68mAcffLAeIpfqk8ls4edfTzAspluTuJdicyd/i0iVUqlUfPPNN7zwwgts2rSJiIgIXnzxRbRaLW+88QYnT57kxx9/5JlnnqGwsNDZ4Uo1oCgK2389wcAeXfD2kHflbgxqNY5Yqvk44qbWNXEjo9HI1KlT2bZtG4cOHSI6Otq+rkePHnzzzTeEhobWMVKpocQdP4+XhxsRYSHODqVZq/dxxFLNqVSqWnURNLTPPvuM8ePHl7sox8vLi6FDh/Ltt9/i5vZbCyo+Ph5FUWQSbkIuXE2nuMTMnZGdnR2KdAOnd02sXr2aDh064OrqSkxMDLt3775l+VWrVtG1a1cMBgPh4eFs2LChQpk33niD8PBwDAYDoaGhPPPMM5hMv7VGly5dikqlKveQIwFKRUREsGDBAsxms33ZmTNnWLVqFS+//DJdupROBJOVlcX06dNZs2aNs0KVaijlWg7nElO5q1eEs0ORbiac6NNPPxU6nU6sXbtWnDx5UsyZM0e4u7uLK1euVFp+9erVwtPTU3z66afiwoULYtOmTcLDw0N89dVX9jIbN24ULi4u4pNPPhGXLl0S33//vQgODhZz5861l1myZIno3r27SE1NtT8yMjJqFHteXp4ARF5eXu0+fCO2detWMWLECDFmzBhx//33iwkTJoh9+/bZ15tMJjF48GCxYcMGJ0Yp1cS1HKP4ame8MFsszg6lxahJjnBqIr7zzjvF7Nmzyy2LiIgQCxYsqLT8gAEDxPz588stmzNnjhg0aJD9/ZNPPinuvvvucmXmzZsn7rrrLvv7JUuWiJ49e9Yp9uaciG9FURTx8MMPiyVLljg7FKmajIVFYuuOX0VhcYmzQ2lRapIjnNY1YTabSUhIqHC57MiRI9m7d2+l25SUlODq6lpumcFgIC4uDovFAsBdd91FQkICcXFxAFy8eJFt27Zx3333ldvu3LlzhISE0KFDBx5++GEuXrx4y3hLSkowGo3lHi3Rnj172Lx5M1u3biU6Opro6GiOHTvm7LCkKshhak1EA/zHUKnk5GQBiD179pRb/vLLL4suXbpUus3ChQtF69atRXx8vFAURfz6668iMDBQACIlJcVe7q233hI6nU5otVoBiD/84Q/l6tm2bZv47LPPxNGjR0VsbKwYOnSoCAoKEpmZmVXGu2TJEgFUeLS0FrHUdJgtVvHfXQkiI1t+R52hSXRNXE/Ee/fuLbd82bJlIjw8vNJtioqKxCOPPCK0Wq3QaDQiJCREPPfccwIQ6enpQgghtm/fLoKCgsTatWvF0aNHxRdffCFCQ0PFSy+9VGUsBQUFIigoSKxYsaLKMiaTSeTl5dkfSUlJMhFLjZbNZhPf7T0iElOrblxI9atJdE34+/uj0WgqXDKbkZFR7r54NzIYDKxbt46ioiIuX75MYmIiYWFheHp64u/vD8DixYuZNm0ajz/+OFFRUUyaNIlXXnmF5cuXoyhKpfW6u7sTFRXFuXPnqozXxcUFLy+vcg9JaoyEEPxy+AxhIQHynnNNhNMSsV6vJyYmhtjY2HLLY2NjGThw4C231el0tG3bFo1Gw6effsr999+PumzCkqKiIvvr6zQaDaK09V9pfSUlJZw6dYrg4OA6fCJJcj4hBPuOnsPL3UB4e/l9biqcekHHvHnzmDZtGn369GHAgAGsWbOGxMREZs+eDcDChQtJTk62jxU+e/YscXFx9OvXj5ycHFauXMnx48dZv369vc5x48axcuVKevXqRb9+/Th//jyLFy9m/Pjx9juKzJ8/n3HjxtGuXTsyMjJYtmwZRqORGTNmNPxBkCQHsVhtbI8/QWhQK7p2kLc6akqcmoinTJlCVlYWL730EqmpqURGRrJt2zb7bF+pqakkJibay9tsNlasWMGZM2fQ6XQMHz6cvXv3EhYWZi+zaNEiVCoVixYtIjk5mYCAAMaNG8fLL79sL3P16lWmTp1KZmYmAQEB9O/fn/3799v3K0lNjbGwmJ0JJ+kV0UHeYaMJknNN1JK8Z53UGAghOH05hfNX0xnSK0JO4tOIyLkmJKkFKDKVsOvQaYJ8vblvUHSFcyNS0yETsSQ1QeeT0jh5MZmBPbvg7+Pp7HCkOpKJWJKaEJPZwi+HTuPpbuC+wb3k7Y2aCZmIJamJuJJ6jcNnr9A/6g6C/LydHY7kQDIRS7eUk5PDhg0biI+Px93dncmTJ1eYH0SqXyVmC/uOnUOr0TB2UC90Wo2zQ5IcTP6ukaq0detWRo8eTWRkJOvWrePxxx9n1KhRHDlyxNmhtRiXU67x3b4jhLcP5q7ocJmEmynZIpYqlZ+fz/Tp0zl27Jh9fHVubi5BQUFyEv0GUFhsYv/x8xhc9LIV3ALIRNxAhBAUm4sbfL8GvaFW96xLT08nPz+f9PR0eyIeMWJEhblBJMcqMVs4dOYy2cYC+nbrRICvHKPeEshE3ECKzcV0eaJ7g+/37JoTuLnUfJB/p06dGDFiBEOGDGH27Nk89dRTdO7cmfz8fO6++24sFgs2m42nn36aWbNm1UPkLYvFauXEhaskpWcR3SWM/lF3ODskqQHJPmKpUiqVim+++YYXXniBTZs2ERERwYsvvoibmxs7d+7k8OHDHDhwgOXLl5OVleXscJuswmIT+46e47t9R/F0N3D/4N5yxrQWSF7iXEs1vcS5qXVN3MhoNDJ16lS2bdvGoUOHiI6OBiA7O5tevXqRkJBgn4ZUuj2bonAlNZOziamoVSoiO4US7O9T57+T1LjIS5wbIZVKVasugob22WefMX78ePT6326r4+XlxdChQ/n2229xc3MjNzeXoUOHcu7cOV5//XWZhKspMzef05dTyDEW0D44gKG9u2JwkbcvkmQilm4SERHBggULePXVV+3J+MyZM6xatYqXX36ZLl26AHDkyBHS09OZPHkyDzzwQJWT+bdkFquN1MwcrqRmkptfiK+XBxFhIfKSZKkCmYilciIjIxk6dCj33XcfOp0OjUaDRqNh8+bN9O/fv1zZoKAgevTowa5du3jwwQedFHHjIYQgN7+IpPQskjOyEQhCAvyI7BSKj6eb7HqQqiT7iGuppU6DmZ6ejsFgwMvLC6PRyIABA9i0aRM9evRwdmgNTgiBsbCY1Mxckq9lU1Rcgq+XB20D/WgT6ItOK9s5LZnsI5bqzdWrV3nsscfst5566qmnWkwSVhSFbGMhqZk5pGbmUmKx4u1uINjfl/6RnXE3uDo7RKmJkolYqpGYmBgOHz7s7DAahMVq5VpOPmlZuaRn5WFTFPy8PQjx9+WO3sG46nXODlFqJmQiliTAbLGSnVdAlrGAjOw8CopL0Gk1BPp6EeTnTVTndvIyY6neyEQstRhWm42CIhPGwmLyC4vJKywmL78IRQh0Wg1+Xh74eXvQt1snPNxkN4PUcGQilpoFm6JgKjFTZDJTZCqhyGS2J9wSixUAjVqFp5sBT3cDXu4GWvv74uPpJidXl5xOJmKpUbIpCiVmCyaz5YZnK0WmEopNZopKzJgtVlQqEALUKhUGVz1uLnoMrnrcXV3o2CYQT3eD7MuVGj2ZiCWHUhQFq03BYrWWPdtKX1tLl1msNqw2G2aLrTS5WkqTrKIo5epRq1S46HW46HW43vAc7O+DwUWPm6sLOq1Gjs2VmgWZiOuouMSMrsRc7fKlo7ZF2fAvUMqGgZWuK10mKHsut1wgyl5zU5mKy8vXww1lFCFQFIFNUVAUBZsisNmuv1ZQFIFVsd1QRmCz2VCqOdxchQqtVoNOq0Gn0fz2WqtBqyl9dnXRoddp7clVr9Oi1cgTYVLLJRNxHcUdv4C7h0e1y6tUpfNOqCh9RlWavNQqVbn3VZVTqcrWlZXhhjJVLy99TVkZnVaDq1qHRq1GrVb99qzRoFGrUKvVaG56b49PkiSHk4m4jobGdG1RV9ZJkuR48nSxJEmSk8lELEmS5GQyEUuSJDmZTMSSJElOJhOxJEmSk8lRE7V0fYyv0Wh0ciSSJDVG13NDdaZ8l4m4lvLz8wEIDQ11ciSSJDVm+fn5eHt737KMvENHLSmKQkpKCp6enhUudOjbty+//vrrLbe/VZnK1lVnWVXvjUYjoaGhJCUlOXTMc3U+Z03Ly+NS8zLyuDTO4yKEID8/n5CQENS3mVhKtohrSa1W07Zt20rXaTSa2/6hblWmsnXVWXa7915eXg79h1Wdz1nT8vK41LyMPC6N97jcriV8nTxZVw+efPLJOpWpbF11lt3uvaPVtH55XGpfXh6XmpdpKscFZNdEi9BSb3R6O/K4VE4el8rV53GRLeIWwMXFhSVLluDi4uLsUBoVeVwqJ49L5erzuMgWsSRJkpPJFrEkSZKTyUQsSZLkZDIRS5IkOZlMxJIkSU4mE7EkSZKTyUQs2SUlJTFs2DC6detGjx49+M9//uPskBqNSZMm4evrywMPPODsUJzq66+/Jjw8nDvuuIMPPvjA2eE0GnX9fsjha5Jdamoq6enpREdHk5GRQe/evTlz5gzu7u7ODs3ptm/fTkFBAevXr+ezzz5zdjhOYbVa6datG9u3b8fLy4vevXtz4MAB/Pz8nB2a09X1+yFbxJJdcHAw0dHRAAQGBuLn50d2drZzg2okhg8fjqenp7PDcKq4uDi6d+9OmzZt8PT0ZOzYsXz//ffODqtRqOv3QybiJmTXrl2MGzeOkJAQVCoVW7durVBm9erVdOjQAVdXV2JiYti9e3et9hUfH4+iKE1ims+GPC5NWV2PU0pKCm3atLG/b9u2LcnJyQ0Rer1qDN8fmYibkMLCQnr27Mk777xT6frNmzczd+5cnn/+eQ4dOsTgwYMZM2YMiYmJ9jIxMTFERkZWeKSkpNjLZGVlMX36dNasWVPvn8kRGuq4NHV1PU6V9WLePAVsU+SI70+dCalJAsSWLVvKLbvzzjvF7Nmzyy2LiIgQCxYsqHa9JpNJDB48WGzYsMERYTa4+jouQgixfft28bvf/a6uITYKtTlOe/bsERMnTrSve/rpp8Unn3xS77E2pLp8f+ry/ZAt4mbCbDaTkJDAyJEjyy0fOXIke/furVYdQghmzpzJ3XffzbRp0+ojzAbniOPSElTnON15550cP36c5ORk8vPz2bZtG6NGjXJGuA2mob4/cmL4ZiIzMxObzUZQUFC55UFBQaSlpVWrjj179rB582Z69Ohh7yf7+OOPiYqKcnS4DcYRxwVg1KhRHDx4kMLCQtq2bcuWLVvo27evo8N1muocJ61Wy4oVKxg+fDiKovDcc8/RqlUrZ4TbYKr7/anr90Mm4mbm5j47IUS1+/HuuusuFEWpj7Ccri7HBWgxowNud5zGjx/P+PHjGzosp7vdcanr90N2TTQT/v7+aDSaCq28jIyMCv+btyTyuFSPPE6Va6jjIhNxM6HX64mJiSE2Nrbc8tjYWAYOHOikqJxPHpfqkcepcg11XGTXRBNSUFDA+fPn7e8vXbrE4cOH8fPzo127dsybN49p06bRp08fBgwYwJo1a0hMTGT27NlOjLr+yeNSPfI4Va5RHJdajbWQnGL79u0CqPCYMWOGvcyqVatE+/bthV6vF7179xY7d+50XsANRB6X6pHHqXKN4bjIuSYkSZKcTPYRS5IkOZlMxJIkSU4mE7EkSZKTyUQsSZLkZDIRS5IkOZlMxJIkSU4mE7EkSZKTyUQsSZLkZDIRS5IkOZlMxJJUz8LCwnjjjTecHYbUiMlELDUrM2fOZOLEiQAMGzaMuXPnNti+P/roI3x8fCos//XXX3niiScaLA6p6ZGzr0nSbZjNZvR6fa23DwgIcGA0UnMkW8RSszRz5kx27tzJm2++iUqlQqVScfnyZQBOnjzJ2LFj8fDwICgoiGnTppGZmWnfdtiwYTz11FPMmzcPf39/7r33XgBWrlxJVFQU7u7uhIaG8sc//pGCggIAduzYwSOPPEJeXp59f0uXLgUqdk0kJiYyYcIEPDw88PLy4qGHHiI9Pd2+funSpURHR/Pxxx8TFhaGt7c3Dz/8MPn5+fYyn332GVFRURgMBlq1asWIESMoLCysp6Mp1TeZiKVm6c0332TAgAHMmjWL1NRUUlNTCQ0NJTU1laFDhxIdHU18fDzfffcd6enpPPTQQ+W2X79+PVqtlj179vD+++8DoFareeuttzh+/Djr16/n559/5rnnngNg4MCBvPHGG3h5edn3N3/+/ApxCSGYOHEi2dnZ7Ny5k9jYWC5cuMCUKVPKlbtw4QJbt27l66+/5uuvv2bnzp28+uqrAKSmpjJ16lQeffRRTp06xY4dO5g8eXKlt7uXmgiHTqopSU42Y8YMMWHCBCGEEEOHDhVz5swpt37x4sVi5MiR5ZYlJSUJQJw5c8a+XXR09G339e9//1u0atXK/v7DDz8U3t7eFcq1b99e/OMf/xBCCPHDDz8IjUYjEhMT7etPnDghABEXFyeEEGLJkiXCzc1NGI1Ge5lnn31W9OvXTwghREJCggDE5cuXbxuj1DTIFrHUoiQkJLB9+3Y8PDzsj4iICKC0FXpdnz59Kmy7fft27r33Xtq0aYOnpyfTp08nKyurRl0Cp06dIjQ0lNDQUPuybt264ePjw6lTp+zLwsLC8PT0tL8PDg4mIyMDgJ49e3LPPfcQFRXFgw8+yNq1a8nJyan+QZAaHZmIpRZFURTGjRvH4cOHyz3OnTvHkCFD7OXc3d3LbXflyhXGjh1LZGQkn3/+OQkJCaxatQoAi8VS7f2LKu4effNynU5Xbr1KpbLfYVuj0RAbG8u3335Lt27dePvttwkPD+fSpUvVjkNqXGQilpotvV6PzWYrt6x3796cOHGCsLAwOnfuXO5xc/K9UXx8PFarlRUrVtC/f3+6dOlCSkrKbfd3s27dupGYmEhSUpJ92cmTJ8nLy6Nr167V/mwqlYpBgwbx4osvcujQIfR6PVu2bKn29lLjIhOx1GyFhYVx4MABLl++TGZmJoqi8OSTT5Kdnc3UqVOJi4vj4sWL/PDDDzz66KO3TKKdOnXCarXy9ttvc/HiRT7++GPee++9CvsrKCjgp59+IjMzk6Kiogr1jBgxgh49evD73/+egwcPEhcXx/Tp0xk6dGil3SGVOXDgAK+88grx8fEkJibyxRdfcO3atRolcqlxkYlYarbmz5+PRqOhW7duBAQEkJiYSEhICHv27MFmszFq1CgiIyOZM2cO3t7eqNVV/3OIjo5m5cqVvPbaa0RGRvLJJ5+wfPnycmUGDhzI7NmzmTJlCgEBAfztb3+rUI9KpWLr1q34+voyZMgQRowYQceOHdm8eXO1P5eXlxe7du1i7NixdOnShUWLFrFixQrGjBlT/YMjNSry5qGSJElOJlvEkiRJTiYTsSRJkpPJRCxJkuRkMhFLkiQ5mUzEkiRJTiYTsSRJkpPJRCxJkuRkMhFLkiQ5mUzEkiRJTiYTsSRJkpPJRCxJkuRk/x8bzyN/iqc8DAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 341.6x221.6 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"#457B9D\", \"#E63946\", \"#2C5675\", \"#A72833\",\"#1B5E20\"]\n",
    "plt.figure(figsize=(3.416, 2.216))\n",
    "\n",
    "dist_samples_1 = np.load(\"realistic_dist_samples_1.npy\")\n",
    "dist_samples_2 = np.load(\"realistic_dist_samples_2.npy\")\n",
    "dist_samples_fc = np.load(\"realistic_dist_samples_fc.npy\")\n",
    "\n",
    "abs = np.linspace(0, epochs, dist_samples_1.shape[1])\n",
    "\n",
    "\n",
    "plt.plot(abs, dist_samples_1.T, color=colors[0], lw=0.5, alpha=0.5)\n",
    "plt.plot(abs, dist_samples_2.T, color=colors[1], lw=0.5, alpha=0.5)\n",
    "plt.plot(abs, dist_samples_fc.T, color=colors[2], lw=0.5, alpha=0.5)\n",
    "\n",
    "plt.plot(abs, dist_samples_1.mean(axis=0), label=r\"$\\mathcal{S}_1$\", color=colors[2])\n",
    "plt.plot(abs, dist_samples_2.mean(axis=0), label=r\"$\\mathcal{S}_2$\", color=colors[3])\n",
    "plt.plot(abs, dist_samples_fc.mean(axis=0), label=r\"$\\mathcal{S}_3$\", color=colors[4])\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
